# Advanced Large Language Models Prompting Strategies for Reentrancy Classification and Explanation in Smart Contracts

This repository contains the official code for the research paper **Advanced Large Language Models Prompting Strategies for Reentrancy Classification and Explanation in Smart Contracts** for smart contract security. Our work introduces a novel approach that combines **structurally-aware RAG** with **reasoning-optimized Large Language Models (LLMs)** to detect vulnerabilities and generate human-understandable explanations.

Our key finding is that grounding LLMs in **structural evidence** (like Control Flow Graphs) is more effective than prescribing a rigid thought process. This method not only achieves **state-of-the-art accuracy** but also produces **trustworthy, actionable explanations**, bridging the gap between automated analysis and human expertise.

## Key Features

  * **Knowledge Base Construction**: Indexed dataset of **smart contracts** categorized as vulnerable or safe.
  * **Retrieval Mechanism**: Uses **AST/CFG-based graph similarity search** to retrieve relevant contract examples.
  * **AI-Driven Classification & Explanation**: **LLMs** process retrieved contracts to generate **context-aware** security insights.
  * **Expert Validation**: Security auditors **review AI-generated explanations** to assess accuracy and usability.

## Experimental Setup

  * **Scope**: Detecting **reentrancy vulnerabilities** in Solidity contracts.
  * **Dataset**: Available [here](https://github.com/matteo-rizzo/manually-verified-reentrancy-dataset).
  * **Models Evaluated**:
      * **Baseline ML**: BERT, LSTM, FFNN, GNB, GB, XGB, KNN, LR, RF, SVM
      * **LLMs**: GPT-4o, GPT-4.1, GPT-4.1-mini, GPT-4.1-nano, o3-mini, o4-mini
      * **RAG Variants**: AST, CFG, AST+CFG retrieval strategies
  * **Prompts**: Available at ``src/prompts.py``

## Results Summary

  * **Model Performance**: LLMs outperform traditional ML models across **accuracy, precision, recall, and F1**.
  * **Effect of Retrieval Data Type**: AST retrieval performs **similarly** to AST+CFG, while CFG alone peaks at a higher k-value.
  * **Effect of Number of Retrieved Contracts**: Best results occur at **K=3**.
  * **Explainability Insights**:
      * LLM-only explanations tend to be **poor and unreliable**.
      * RAG explanations are **more accurate** but require **further refinement**.
      * Expert feedback integration is key to improving **trust in AI-driven assessments**.

## Future Research Directions

  * **Expanding the Knowledge Base** with **more diverse, real-world contracts** and **synthetic datasets generated by LLMs**.
  * **Exploring More Advanced LLMs** with **reasoning capabilities** (e.g., Deep Seek) and testing **local AI models**.
  * **Refining Retrieval Strategies** using **graph-based refinements and context-aware embeddings**.
  * **Automating Expert Validation** through **reinforcement learning and AI self-improvement cycles**.

## Installation & Usage

### Prerequisites

  * Python 3.8+
  * Install dependencies:
    ```bash
    pip install -r requirements.txt
    ```
  * Set up your OpenAI API key in `src/.env` (if using GPT models).

### Running the Pipeline

1.  **Run the RAG pipeline**:
    ```bash
    ./src/scripts/xrag.sh
    ```
2.  **Generate baseline explanations**:
    ```bash
    ./src/scripts/baseline.sh
    ```
3.  **Analyze results** in the Jupyter Notebook:
    ```bash
    jupyter notebook notebooks/rag-results.ipynb
    ```

## License

This project is licensed under the MIT License - see the [LICENSE](https://www.google.com/search?q=LICENSE) file for details.