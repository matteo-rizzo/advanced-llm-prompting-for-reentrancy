{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T06:50:44.903318Z",
     "start_time": "2025-06-12T06:50:44.894204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import logging\n",
    "import json\n",
    "import colorlog\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define a color formatter\n",
    "formatter = colorlog.ColoredFormatter(\n",
    "    \"%(log_color)s%(levelname)s: %(message)s\",\n",
    "    log_colors={\n",
    "        \"DEBUG\": \"cyan\",\n",
    "        \"INFO\": \"green\",\n",
    "        \"WARNING\": \"yellow\",\n",
    "        \"ERROR\": \"red\",\n",
    "        \"CRITICAL\": \"bold_red\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# Create a logger\n",
    "logger = logging.getLogger(__name__)  # Use module-level logger\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.propagate = False  # Prevent propagation to root logger\n",
    "\n",
    "# Remove all existing handlers (even from previous executions)\n",
    "logger.handlers.clear()\n",
    "\n",
    "# Create a stream handler and set the formatter\n",
    "handler = logging.StreamHandler()\n",
    "handler.setFormatter(formatter)\n",
    "\n",
    "# Add the new handler\n",
    "logger.addHandler(handler)"
   ],
   "id": "13611561371d75dd",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T06:50:44.934455Z",
     "start_time": "2025-06-12T06:50:44.926934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "monitored_metrics = [\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"]\n",
    "data_types = [\"ast_cfg\", \"ast\", \"cfg\"]\n",
    "base_folder = \"../explanations\"\n",
    "columns = [\"Data Type\"] + monitored_metrics\n",
    "sns.set_palette(\"tab10\")"
   ],
   "id": "ba064a2a5dab940e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-12T06:50:44.955086Z",
     "start_time": "2025-06-12T06:50:44.948207Z"
    }
   },
   "source": [
    "def get_json_files(directory):\n",
    "    \"\"\"Retrieves all JSON file paths in a given directory.\"\"\"\n",
    "    try:\n",
    "        return [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith(\".json\")]\n",
    "    except FileNotFoundError:\n",
    "        logger.warning(f\"Directory not found: {directory}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def load_json(file_path):\n",
    "    \"\"\"Loads a JSON file and returns its content.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            return json.load(file)\n",
    "    except (json.JSONDecodeError, FileNotFoundError, KeyError) as e:\n",
    "        logger.error(f\"Error processing file '{file_path}': {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def compute_category_metrics(directory, gt_category):\n",
    "    \"\"\"\n",
    "    Computes Accuracy, Precision, Recall, and F1-score for a category using sklearn.\n",
    "\n",
    "    :param directory: Path to the directory containing JSON log files.\n",
    "    :param gt_category: The ground truth category.\n",
    "    :return: Dictionary containing accuracy, precision, recall, and f1-score.\n",
    "    \"\"\"\n",
    "    json_files = get_json_files(directory)\n",
    "    total_files = len(json_files)\n",
    "\n",
    "    if total_files == 0:\n",
    "        return {\"Accuracy\": 0.0, \"Precision\": 0.0, \"Recall\": 0.0, \"F1 Score\": 0.0, \"Total\": 0}\n",
    "\n",
    "    gt_category = gt_category.lower()\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    for file in json_files:\n",
    "        content = load_json(file)\n",
    "        if not content:\n",
    "            continue\n",
    "\n",
    "        predicted_category = content.get(\"classification\", \"\").lower()\n",
    "        y_true.append(gt_category)\n",
    "        y_pred.append(predicted_category)\n",
    "\n",
    "    # Compute metrics using sklearn\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average=\"binary\", pos_label=gt_category, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, average=\"binary\", pos_label=gt_category, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average=\"binary\", pos_label=gt_category, zero_division=0)\n",
    "\n",
    "    return {\"Accuracy\": accuracy, \"Precision\": precision, \"Recall\": recall, \"F1 Score\": f1, \"Total\": total_files}\n",
    "\n",
    "\n",
    "def compute_overall_metrics(results):\n",
    "    \"\"\"\n",
    "    Computes overall Accuracy, Precision, Recall, and F1-score across multiple categories.\n",
    "\n",
    "    :param results: Dictionary of category-wise metric results.\n",
    "    :return: Dictionary containing overall accuracy, precision, recall, and f1-score.\n",
    "    \"\"\"\n",
    "    total_all = sum(res[\"Total\"] for res in results.values())\n",
    "\n",
    "    if total_all == 0:\n",
    "        logger.warning(\"No JSON files found in any category.\")\n",
    "        return {\"Accuracy\": 0.0, \"Precision\": 0.0, \"Recall\": 0.0, \"F1 Score\": 0.0}\n",
    "\n",
    "    # Weighted average of all metrics\n",
    "    weighted_metrics = {key: sum(res[key] * res[\"Total\"] for res in results.values()) / total_all for key in\n",
    "                        monitored_metrics}\n",
    "\n",
    "    return weighted_metrics"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Baseline",
   "id": "ee15791cc0d1159d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T06:50:46.064422Z",
     "start_time": "2025-06-12T06:50:44.972204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    # classification_report # Could be useful for verbose printing per fold\n",
    ")\n",
    "\n",
    "# --- Logger Setup (Basic) ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "# --- Utility Functions (get_json_files, load_json remain the same) ---\n",
    "def get_json_files(directory):\n",
    "    \"\"\"Retrieves all JSON file paths in a given directory.\"\"\"\n",
    "    try:\n",
    "        return [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith(\".json\")]\n",
    "    except FileNotFoundError:\n",
    "        logger.warning(f\"Directory not found: {directory}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def load_json(file_path):\n",
    "    \"\"\"Loads a JSON file and returns its content.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            return json.load(file)\n",
    "    except (json.JSONDecodeError, FileNotFoundError, KeyError) as e:\n",
    "        logger.error(f\"Error processing file '{file_path}': {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# --- Main Script ---\n",
    "base_folder = \"../explanations/prompting/baseline\"  # Make sure this path is correct\n",
    "num_folds = 3\n",
    "\n",
    "# --- 1. Identify Models and Categories ---\n",
    "fold_dirs = [os.path.join(base_folder, f\"cv_{i + 1}\") for i in range(num_folds)]\n",
    "first_fold_dir = fold_dirs[0]\n",
    "\n",
    "if not os.path.exists(first_fold_dir):\n",
    "    logger.error(f\"First fold directory not found: {first_fold_dir}\")\n",
    "    exit()\n",
    "\n",
    "available_models = [\n",
    "    model_dir for model_dir in os.listdir(first_fold_dir)\n",
    "    if os.path.isdir(os.path.join(first_fold_dir, model_dir))\n",
    "]\n",
    "\n",
    "if not available_models:\n",
    "    logger.info(f\"No model directories found in {first_fold_dir}\")\n",
    "    exit()\n",
    "\n",
    "logger.info(f\"Found models: {available_models}\")\n",
    "\n",
    "baseline_results = {}  # To store aggregated mean/std dev results\n",
    "\n",
    "# Define overall metrics to be tracked and averaged\n",
    "overall_metric_keys = [\n",
    "    \"Accuracy\",\n",
    "    \"Precision_weighted\",\n",
    "    \"Recall_weighted\",\n",
    "    \"F1 Score_weighted\"\n",
    "]\n",
    "\n",
    "for model_name in available_models:\n",
    "    logger.info(f\"\\n===== PROCESSING MODEL: {model_name} =====\")\n",
    "\n",
    "    model_fold_metrics = defaultdict(lambda: defaultdict(list))\n",
    "    all_true_categories_for_model = set()  # To collect all unique true category names like {'reentrant', 'safe'}\n",
    "\n",
    "    for i, fold_dir_path in enumerate(fold_dirs):\n",
    "        fold_num = i + 1\n",
    "        model_path_in_fold = os.path.join(fold_dir_path, model_name)\n",
    "        logger.info(f\"\\n  --- Processing Fold {fold_num} ({model_path_in_fold}) ---\")\n",
    "\n",
    "        if not os.path.exists(model_path_in_fold):\n",
    "            logger.warning(f\"  Model directory not found in this fold: {model_path_in_fold}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            categories_in_fold_model_dir = {\n",
    "                subdir: os.path.join(model_path_in_fold, subdir)\n",
    "                for subdir in os.listdir(model_path_in_fold)\n",
    "                if os.path.isdir(os.path.join(model_path_in_fold, subdir))\n",
    "            }\n",
    "        except FileNotFoundError:\n",
    "            logger.error(f\"  Error listing categories in: {model_path_in_fold}\")\n",
    "            continue\n",
    "\n",
    "        if not categories_in_fold_model_dir:\n",
    "            logger.warning(f\"  No category subdirectories found in {model_path_in_fold}\")\n",
    "            continue\n",
    "\n",
    "        y_true_for_fold = []\n",
    "        y_pred_for_fold = []\n",
    "        current_fold_true_categories = set()  # True categories present in this specific fold\n",
    "\n",
    "        for true_category_name, category_path in categories_in_fold_model_dir.items():\n",
    "            true_category_lower = true_category_name.lower()\n",
    "\n",
    "            # Basic check for expected binary labels from directory names\n",
    "            if true_category_lower not in [\"reentrant\", \"safe\"]:\n",
    "                logger.warning(\n",
    "                    f\"    Unexpected category directory name found: {true_category_name}. Expected 'reentrant' or 'safe'. Skipping this directory.\")\n",
    "                continue\n",
    "\n",
    "            current_fold_true_categories.add(true_category_lower)\n",
    "            all_true_categories_for_model.add(true_category_lower)\n",
    "\n",
    "            json_files = get_json_files(category_path)\n",
    "            if not json_files:\n",
    "                logger.warning(f\"    No JSON files found in {category_path} for category '{true_category_name}'\")\n",
    "                continue\n",
    "\n",
    "            for file_path in json_files:\n",
    "                content = load_json(file_path)\n",
    "                if not content:\n",
    "                    continue\n",
    "\n",
    "                predicted_category = content.get(\"classification\", \"\").lower()\n",
    "                if not predicted_category:\n",
    "                    predicted_category = \"unknown_prediction\"  # Or some other placeholder\n",
    "\n",
    "                y_true_for_fold.append(true_category_lower)\n",
    "                y_pred_for_fold.append(predicted_category)\n",
    "\n",
    "        if not y_true_for_fold:\n",
    "            logger.warning(\n",
    "                f\"  No data collected for model {model_name} in fold {fold_num}. Metrics for this fold will be NaN.\")\n",
    "            continue\n",
    "\n",
    "        # --- Calculate metrics for the current fold ---\n",
    "        unique_labels_in_fold = sorted(list(set(y_true_for_fold) | set(y_pred_for_fold)))\n",
    "\n",
    "        # Overall metrics for this fold\n",
    "        fold_overall_metrics = {}\n",
    "        fold_overall_metrics[\"Accuracy\"] = accuracy_score(y_true_for_fold, y_pred_for_fold)\n",
    "\n",
    "        fold_overall_metrics[\"Precision_weighted\"] = precision_score(\n",
    "            y_true_for_fold, y_pred_for_fold,\n",
    "            labels=unique_labels_in_fold, average='weighted', zero_division=0\n",
    "        )\n",
    "        fold_overall_metrics[\"Recall_weighted\"] = recall_score(\n",
    "            y_true_for_fold, y_pred_for_fold,\n",
    "            labels=unique_labels_in_fold, average='weighted', zero_division=0\n",
    "        )\n",
    "        fold_overall_metrics[\"F1 Score_weighted\"] = f1_score(\n",
    "            y_true_for_fold, y_pred_for_fold,\n",
    "            labels=unique_labels_in_fold, average='weighted', zero_division=0\n",
    "        )\n",
    "\n",
    "        logger.info(f\"  Fold {fold_num} Overall - \"\n",
    "                    f\"Acc: {fold_overall_metrics['Accuracy']:.2%}, \"\n",
    "                    f\"Prec (weighted): {fold_overall_metrics['Precision_weighted']:.2%}, \"\n",
    "                    f\"Rec (weighted): {fold_overall_metrics['Recall_weighted']:.2%}, \"\n",
    "                    f\"F1 (weighted): {fold_overall_metrics['F1 Score_weighted']:.2%}\")\n",
    "\n",
    "        for key, value in fold_overall_metrics.items():\n",
    "            model_fold_metrics['overall'][key].append(value)\n",
    "\n",
    "        # Per-category metrics for this fold (for both \"reentrant\" and \"safe\")\n",
    "        fold_per_category_metrics = {}\n",
    "        sorted_true_categories_in_fold = sorted(list(current_fold_true_categories))\n",
    "\n",
    "        for cat_name in sorted_true_categories_in_fold:  # Should be 'reentrant' and/or 'safe'\n",
    "            if cat_name not in unique_labels_in_fold:\n",
    "                prec, rec, f1, support = np.nan, np.nan, np.nan, 0\n",
    "                logger.warning(\n",
    "                    f\"    Category '{cat_name}' (true label) not in unique_labels_in_fold for fold {fold_num}. Setting its metrics to NaN/0.\")\n",
    "            else:\n",
    "                prec = precision_score(y_true_for_fold, y_pred_for_fold, labels=unique_labels_in_fold,\n",
    "                                       pos_label=cat_name, average='binary', zero_division=0)\n",
    "                rec = recall_score(y_true_for_fold, y_pred_for_fold, labels=unique_labels_in_fold, pos_label=cat_name,\n",
    "                                   average='binary', zero_division=0)\n",
    "                f1 = f1_score(y_true_for_fold, y_pred_for_fold, labels=unique_labels_in_fold, pos_label=cat_name,\n",
    "                              average='binary', zero_division=0)\n",
    "                support = y_true_for_fold.count(cat_name)\n",
    "\n",
    "            fold_per_category_metrics[cat_name] = {\"Precision\": prec, \"Recall\": rec, \"F1 Score\": f1, \"Support\": support}\n",
    "            logger.info(f\"    Cat '{cat_name}': P: {prec:.2%}, R: {rec:.2%}, F1: {f1:.2%}, Sup: {support}\")\n",
    "\n",
    "            model_fold_metrics[cat_name][\"Precision\"].append(prec)\n",
    "            model_fold_metrics[cat_name][\"Recall\"].append(rec)\n",
    "            model_fold_metrics[cat_name][\"F1 Score\"].append(f1)\n",
    "            model_fold_metrics[cat_name][\"Support\"].append(support)\n",
    "\n",
    "    # --- 3. Calculate Mean and Std Dev for the current model ---\n",
    "    expected_categories_for_model = sorted(list(all_true_categories_for_model))\n",
    "\n",
    "    for key_to_summarize in expected_categories_for_model + ['overall']:\n",
    "        metric_names_to_check = []\n",
    "        if key_to_summarize == 'overall':\n",
    "            metric_names_to_check = overall_metric_keys\n",
    "        else:  # per-category\n",
    "            metric_names_to_check = [\"Precision\", \"Recall\", \"F1 Score\", \"Support\"]\n",
    "\n",
    "        for metric_name in metric_names_to_check:\n",
    "            current_values = model_fold_metrics[key_to_summarize].get(metric_name, [])\n",
    "            while len(current_values) < num_folds:\n",
    "                current_values.append(np.nan if metric_name != \"Support\" else 0)\n",
    "            model_fold_metrics[key_to_summarize][metric_name] = current_values[:num_folds]\n",
    "\n",
    "    logger.info(f\"\\n  --- Aggregated Results for Model: {model_name} (across {num_folds} folds) ---\")\n",
    "    model_summary = {}\n",
    "\n",
    "    category_keys_to_process = expected_categories_for_model + ['overall']\n",
    "\n",
    "    for key_to_summarize in category_keys_to_process:\n",
    "        if not model_fold_metrics[key_to_summarize]:\n",
    "            logger.info(f\"    No data to aggregate for '{key_to_summarize.capitalize()}'.\")\n",
    "            continue\n",
    "\n",
    "        summary_metrics = {}\n",
    "        logger.info(f\"    {key_to_summarize.capitalize()}:\")\n",
    "\n",
    "        metrics_to_aggregate_names = overall_metric_keys if key_to_summarize == 'overall' else [\"Precision\", \"Recall\",\n",
    "                                                                                                \"F1 Score\", \"Support\"]\n",
    "\n",
    "        for metric_name in metrics_to_aggregate_names:\n",
    "            values = model_fold_metrics[key_to_summarize].get(metric_name, [np.nan] * num_folds)\n",
    "\n",
    "            valid_values = [v for v in values if not np.isnan(v)]\n",
    "            num_processed_folds = len(values)\n",
    "            num_valid_folds = len(valid_values)\n",
    "\n",
    "            if num_valid_folds > 0:\n",
    "                mean_val = np.mean(valid_values)\n",
    "                std_dev = np.std(valid_values) if num_valid_folds > 1 else 0.0\n",
    "                summary_metrics[f\"{metric_name}_mean\"] = mean_val\n",
    "                summary_metrics[f\"{metric_name}_std\"] = std_dev\n",
    "                if metric_name == \"Support\":\n",
    "                    logger.info(\n",
    "                        f\"      {metric_name}: {mean_val:.2f} ± {std_dev:.2f} (from {num_valid_folds}/{num_processed_folds} folds)\")\n",
    "                else:\n",
    "                    logger.info(\n",
    "                        f\"      {metric_name}: {mean_val:.2%} ± {std_dev:.2%} (from {num_valid_folds}/{num_processed_folds} folds)\")\n",
    "            else:\n",
    "                summary_metrics[f\"{metric_name}_mean\"] = np.nan\n",
    "                summary_metrics[f\"{metric_name}_std\"] = np.nan\n",
    "                logger.info(f\"      {metric_name}: N/A (No valid data across {num_processed_folds} folds)\")\n",
    "\n",
    "        model_summary[key_to_summarize] = summary_metrics\n",
    "    baseline_results[model_name] = model_summary\n",
    "\n",
    "# --- 4. Print Final Summary Table & Save CSV ---\n",
    "logger.info(\"\\n\\n===== FINAL CROSS-VALIDATION SUMMARY (Overall Weighted Metrics & Accuracy) =====\")\n",
    "final_summary_for_csv = {}\n",
    "\n",
    "for model_name, summary_data in baseline_results.items():\n",
    "    logger.info(f\"\\n--- Model: {model_name} ---\")\n",
    "    if 'overall' in summary_data and summary_data['overall']:\n",
    "        overall_metrics_summary = summary_data['overall']  # Renamed for clarity\n",
    "        final_summary_for_csv[model_name] = overall_metrics_summary\n",
    "        logger.info(f\"  Overall Performance (Accuracy & Weighted Averages):\")\n",
    "        logger.info(\n",
    "            f\"    Accuracy:  {overall_metrics_summary.get('Accuracy_mean', np.nan):.2%} ± {overall_metrics_summary.get('Accuracy_std', np.nan):.2%}\")\n",
    "        logger.info(\n",
    "            f\"    Precision (weighted): {overall_metrics_summary.get('Precision_weighted_mean', np.nan):.2%} ± {overall_metrics_summary.get('Precision_weighted_std', np.nan):.2%}\")\n",
    "        logger.info(\n",
    "            f\"    Recall (weighted):    {overall_metrics_summary.get('Recall_weighted_mean', np.nan):.2%} ± {overall_metrics_summary.get('Recall_weighted_std', np.nan):.2%}\")\n",
    "        logger.info(\n",
    "            f\"    F1 Score (weighted):  {overall_metrics_summary.get('F1 Score_weighted_mean', np.nan):.2%} ± {overall_metrics_summary.get('F1 Score_weighted_std', np.nan):.2%}\")\n",
    "    else:\n",
    "        logger.info(f\"  No overall metrics summary available for {model_name}.\")\n",
    "\n",
    "if final_summary_for_csv:\n",
    "    df_summary = pd.DataFrame.from_dict(final_summary_for_csv, orient='index')\n",
    "\n",
    "    csv_columns_ordered = []\n",
    "    for metric_base_name in overall_metric_keys:\n",
    "        csv_columns_ordered.append(f\"{metric_base_name}_mean\")\n",
    "        csv_columns_ordered.append(f\"{metric_base_name}_std\")\n",
    "\n",
    "    df_summary = df_summary.reindex(columns=csv_columns_ordered)\n",
    "\n",
    "    try:\n",
    "        output_csv_name = \"baseline_classification_weighted_metrics.csv\"\n",
    "        df_summary.to_csv(output_csv_name)\n",
    "        logger.info(f\"\\nSaved {output_csv_name}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error saving CSV: {e}\")\n",
    "else:\n",
    "    logger.info(\"\\nNo data to save to CSV.\")\n",
    "\n",
    "logger.info(\"\\nProcessing Complete.\")"
   ],
   "id": "a712e3ec321ab4f8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mINFO: Found models: ['gpt-4.1-nano', 'o4-mini', 'gpt-4.1', 'gpt-4o', 'o3-mini', 'gpt-4.1-mini', 'gemini-1.5-flash', 'gemini-2.5-flash-preview-05-20', 'gemini-2.0-flash']\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "===== PROCESSING MODEL: gpt-4.1-nano =====\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 1 (../explanations/prompting/baseline/cv_1/gpt-4.1-nano) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 1 Overall - Acc: 71.92%, Prec (weighted): 51.72%, Rec (weighted): 71.92%, F1 (weighted): 60.17%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 0.00%, R: 0.00%, F1: 0.00%, Sup: 41\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 71.92%, R: 100.00%, F1: 83.67%, Sup: 105\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 2 (../explanations/prompting/baseline/cv_2/gpt-4.1-nano) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 2 Overall - Acc: 71.92%, Prec (weighted): 51.72%, Rec (weighted): 71.92%, F1 (weighted): 60.17%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 0.00%, R: 0.00%, F1: 0.00%, Sup: 41\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 71.92%, R: 100.00%, F1: 83.67%, Sup: 105\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 3 (../explanations/prompting/baseline/cv_3/gpt-4.1-nano) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 3 Overall - Acc: 72.92%, Prec (weighted): 80.30%, Rec (weighted): 72.92%, F1 (weighted): 62.17%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 100.00%, R: 2.50%, F1: 4.88%, Sup: 40\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 72.73%, R: 100.00%, F1: 84.21%, Sup: 104\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Aggregated Results for Model: gpt-4.1-nano (across 3 folds) ---\u001B[0m\n",
      "\u001B[32mINFO:     Reentrant:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 33.33% ± 47.14% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 0.83% ± 1.18% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 1.63% ± 2.30% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 40.67 ± 0.47 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Safe:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 72.19% ± 0.38% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 100.00% ± 0.00% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 83.85% ± 0.26% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 104.67 ± 0.47 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Overall:\u001B[0m\n",
      "\u001B[32mINFO:       Accuracy: 72.25% ± 0.47% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Precision_weighted: 61.25% ± 13.47% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall_weighted: 72.25% ± 0.47% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score_weighted: 60.84% ± 0.94% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "===== PROCESSING MODEL: o4-mini =====\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 1 (../explanations/prompting/baseline/cv_1/o4-mini) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 1 Overall - Acc: 93.15%, Prec (weighted): 93.42%, Rec (weighted): 93.15%, F1 (weighted): 92.91%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 96.97%, R: 78.05%, F1: 86.49%, Sup: 41\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 92.04%, R: 99.05%, F1: 95.41%, Sup: 105\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 2 (../explanations/prompting/baseline/cv_2/o4-mini) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 2 Overall - Acc: 95.21%, Prec (weighted): 95.51%, Rec (weighted): 95.21%, F1 (weighted): 95.06%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 100.00%, R: 82.93%, F1: 90.67%, Sup: 41\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 93.75%, R: 100.00%, F1: 96.77%, Sup: 105\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 3 (../explanations/prompting/baseline/cv_3/o4-mini) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 3 Overall - Acc: 90.97%, Prec (weighted): 91.98%, Rec (weighted): 90.97%, F1 (weighted): 90.36%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 100.00%, R: 67.50%, F1: 80.60%, Sup: 40\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 88.89%, R: 100.00%, F1: 94.12%, Sup: 104\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Aggregated Results for Model: o4-mini (across 3 folds) ---\u001B[0m\n",
      "\u001B[32mINFO:     Reentrant:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 98.99% ± 1.43% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 76.16% ± 6.44% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 85.92% ± 4.13% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 40.67 ± 0.47 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Safe:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 91.56% ± 2.01% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 99.68% ± 0.45% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 95.43% ± 1.08% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 104.67 ± 0.47 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Overall:\u001B[0m\n",
      "\u001B[32mINFO:       Accuracy: 93.11% ± 1.73% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Precision_weighted: 93.63% ± 1.45% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall_weighted: 93.11% ± 1.73% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score_weighted: 92.78% ± 1.92% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "===== PROCESSING MODEL: gpt-4.1 =====\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 1 (../explanations/prompting/baseline/cv_1/gpt-4.1) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 1 Overall - Acc: 88.36%, Prec (weighted): 90.14%, Rec (weighted): 88.36%, F1 (weighted): 88.72%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 73.08%, R: 92.68%, F1: 81.72%, Sup: 41\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 96.81%, R: 86.67%, F1: 91.46%, Sup: 105\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 2 (../explanations/prompting/baseline/cv_2/gpt-4.1) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 2 Overall - Acc: 89.04%, Prec (weighted): 91.55%, Rec (weighted): 89.04%, F1 (weighted): 89.45%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 72.73%, R: 97.56%, F1: 83.33%, Sup: 41\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 98.90%, R: 85.71%, F1: 91.84%, Sup: 105\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 3 (../explanations/prompting/baseline/cv_3/gpt-4.1) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 3 Overall - Acc: 84.72%, Prec (weighted): 88.74%, Rec (weighted): 84.72%, F1 (weighted): 85.40%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 65.52%, R: 95.00%, F1: 77.55%, Sup: 40\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 97.67%, R: 80.77%, F1: 88.42%, Sup: 104\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Aggregated Results for Model: gpt-4.1 (across 3 folds) ---\u001B[0m\n",
      "\u001B[32mINFO:     Reentrant:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 70.44% ± 3.48% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 95.08% ± 1.99% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 80.87% ± 2.44% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 40.67 ± 0.47 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Safe:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 97.79% ± 0.86% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 84.38% ± 2.59% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 90.57% ± 1.53% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 104.67 ± 0.47 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Overall:\u001B[0m\n",
      "\u001B[32mINFO:       Accuracy: 87.37% ± 1.90% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Precision_weighted: 90.15% ± 1.15% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall_weighted: 87.37% ± 1.90% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score_weighted: 87.86% ± 1.76% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "===== PROCESSING MODEL: gpt-4o =====\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 1 (../explanations/prompting/baseline/cv_1/gpt-4o) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 1 Overall - Acc: 86.99%, Prec (weighted): 91.11%, Rec (weighted): 86.99%, F1 (weighted): 87.56%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 68.33%, R: 100.00%, F1: 81.19%, Sup: 41\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 100.00%, R: 81.90%, F1: 90.05%, Sup: 105\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 2 (../explanations/prompting/baseline/cv_2/gpt-4o) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 2 Overall - Acc: 86.30%, Prec (weighted): 89.52%, Rec (weighted): 86.30%, F1 (weighted): 86.85%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 68.42%, R: 95.12%, F1: 79.59%, Sup: 41\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 97.75%, R: 82.86%, F1: 89.69%, Sup: 105\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 3 (../explanations/prompting/baseline/cv_3/gpt-4o) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 3 Overall - Acc: 81.94%, Prec (weighted): 86.77%, Rec (weighted): 81.94%, F1 (weighted): 82.79%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 61.67%, R: 92.50%, F1: 74.00%, Sup: 40\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 96.43%, R: 77.88%, F1: 86.17%, Sup: 104\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Aggregated Results for Model: gpt-4o (across 3 folds) ---\u001B[0m\n",
      "\u001B[32mINFO:     Reentrant:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 66.14% ± 3.16% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 95.87% ± 3.11% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 78.26% ± 3.08% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 40.67 ± 0.47 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Safe:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 98.06% ± 1.47% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 80.88% ± 2.15% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 88.64% ± 1.75% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 104.67 ± 0.47 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Overall:\u001B[0m\n",
      "\u001B[32mINFO:       Accuracy: 85.08% ± 2.23% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Precision_weighted: 89.13% ± 1.79% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall_weighted: 85.08% ± 2.23% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score_weighted: 85.74% ± 2.10% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "===== PROCESSING MODEL: o3-mini =====\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 1 (../explanations/prompting/baseline/cv_1/o3-mini) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 1 Overall - Acc: 95.21%, Prec (weighted): 95.30%, Rec (weighted): 95.21%, F1 (weighted): 95.11%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 97.22%, R: 85.37%, F1: 90.91%, Sup: 41\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 94.55%, R: 99.05%, F1: 96.74%, Sup: 105\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 2 (../explanations/prompting/baseline/cv_2/o3-mini) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 2 Overall - Acc: 96.58%, Prec (weighted): 96.56%, Rec (weighted): 96.58%, F1 (weighted): 96.56%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 95.00%, R: 92.68%, F1: 93.83%, Sup: 41\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 97.17%, R: 98.10%, F1: 97.63%, Sup: 105\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 3 (../explanations/prompting/baseline/cv_3/o3-mini) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 3 Overall - Acc: 95.14%, Prec (weighted): 95.23%, Rec (weighted): 95.14%, F1 (weighted): 95.03%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 97.14%, R: 85.00%, F1: 90.67%, Sup: 40\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 94.50%, R: 99.04%, F1: 96.71%, Sup: 104\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Aggregated Results for Model: o3-mini (across 3 folds) ---\u001B[0m\n",
      "\u001B[32mINFO:     Reentrant:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 96.46% ± 1.03% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 87.68% ± 3.54% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 91.80% ± 1.44% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 40.67 ± 0.47 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Safe:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 95.40% ± 1.25% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 98.73% ± 0.45% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 97.03% ± 0.43% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 104.67 ± 0.47 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Overall:\u001B[0m\n",
      "\u001B[32mINFO:       Accuracy: 95.64% ± 0.66% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Precision_weighted: 95.70% ± 0.61% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall_weighted: 95.64% ± 0.66% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score_weighted: 95.57% ± 0.70% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "===== PROCESSING MODEL: gpt-4.1-mini =====\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 1 (../explanations/prompting/baseline/cv_1/gpt-4.1-mini) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 1 Overall - Acc: 85.62%, Prec (weighted): 86.46%, Rec (weighted): 85.62%, F1 (weighted): 84.27%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 91.67%, R: 53.66%, F1: 67.69%, Sup: 41\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 84.43%, R: 98.10%, F1: 90.75%, Sup: 105\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 2 (../explanations/prompting/baseline/cv_2/gpt-4.1-mini) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 2 Overall - Acc: 88.36%, Prec (weighted): 89.33%, Rec (weighted): 88.36%, F1 (weighted): 87.44%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 96.15%, R: 60.98%, F1: 74.63%, Sup: 41\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 86.67%, R: 99.05%, F1: 92.44%, Sup: 105\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 3 (../explanations/prompting/baseline/cv_3/gpt-4.1-mini) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 3 Overall - Acc: 85.42%, Prec (weighted): 87.87%, Rec (weighted): 85.42%, F1 (weighted): 83.49%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 100.00%, R: 47.50%, F1: 64.41%, Sup: 40\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 83.20%, R: 100.00%, F1: 90.83%, Sup: 104\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Aggregated Results for Model: gpt-4.1-mini (across 3 folds) ---\u001B[0m\n",
      "\u001B[32mINFO:     Reentrant:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 95.94% ± 3.41% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 54.04% ± 5.51% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 68.91% ± 4.26% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 40.67 ± 0.47 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Safe:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 84.76% ± 1.44% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 99.05% ± 0.78% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 91.34% ± 0.78% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 104.67 ± 0.47 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Overall:\u001B[0m\n",
      "\u001B[32mINFO:       Accuracy: 86.46% ± 1.34% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Precision_weighted: 87.89% ± 1.17% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall_weighted: 86.46% ± 1.34% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score_weighted: 85.07% ± 1.71% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "===== PROCESSING MODEL: gemini-1.5-flash =====\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 1 (../explanations/prompting/baseline/cv_1/gemini-1.5-flash) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 1 Overall - Acc: 78.08%, Prec (weighted): 78.46%, Rec (weighted): 78.08%, F1 (weighted): 74.20%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 80.00%, R: 29.27%, F1: 42.86%, Sup: 41\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 77.86%, R: 97.14%, F1: 86.44%, Sup: 105\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 2 (../explanations/prompting/baseline/cv_2/gemini-1.5-flash) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 2 Overall - Acc: 80.82%, Prec (weighted): 83.31%, Rec (weighted): 80.82%, F1 (weighted): 77.43%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 93.33%, R: 34.15%, F1: 50.00%, Sup: 41\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 79.39%, R: 99.05%, F1: 88.14%, Sup: 105\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 3 (../explanations/prompting/baseline/cv_3/gemini-1.5-flash) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 3 Overall - Acc: 84.03%, Prec (weighted): 86.92%, Rec (weighted): 84.03%, F1 (weighted): 81.60%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 100.00%, R: 42.50%, F1: 59.65%, Sup: 40\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 81.89%, R: 100.00%, F1: 90.04%, Sup: 104\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Aggregated Results for Model: gemini-1.5-flash (across 3 folds) ---\u001B[0m\n",
      "\u001B[32mINFO:     Reentrant:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 91.11% ± 8.31% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 35.30% ± 5.46% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 50.84% ± 6.88% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 40.67 ± 0.47 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Safe:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 79.71% ± 1.66% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 98.73% ± 1.19% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 88.21% ± 1.47% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 104.67 ± 0.47 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Overall:\u001B[0m\n",
      "\u001B[32mINFO:       Accuracy: 80.98% ± 2.43% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Precision_weighted: 82.90% ± 3.46% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall_weighted: 80.98% ± 2.43% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score_weighted: 77.74% ± 3.03% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "===== PROCESSING MODEL: gemini-2.5-flash-preview-05-20 =====\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 1 (../explanations/prompting/baseline/cv_1/gemini-2.5-flash-preview-05-20) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 1 Overall - Acc: 82.88%, Prec (weighted): 85.43%, Rec (weighted): 82.88%, F1 (weighted): 83.48%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 64.81%, R: 85.37%, F1: 73.68%, Sup: 41\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 93.48%, R: 81.90%, F1: 87.31%, Sup: 105\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 2 (../explanations/prompting/baseline/cv_2/gemini-2.5-flash-preview-05-20) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 2 Overall - Acc: 86.99%, Prec (weighted): 88.39%, Rec (weighted): 86.99%, F1 (weighted): 87.34%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 72.00%, R: 87.80%, F1: 79.12%, Sup: 41\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 94.79%, R: 86.67%, F1: 90.55%, Sup: 105\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 3 (../explanations/prompting/baseline/cv_3/gemini-2.5-flash-preview-05-20) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 3 Overall - Acc: 77.08%, Prec (weighted): 80.58%, Rec (weighted): 77.08%, F1 (weighted): 78.00%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 56.36%, R: 77.50%, F1: 65.26%, Sup: 40\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 89.89%, R: 76.92%, F1: 82.90%, Sup: 104\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Aggregated Results for Model: gemini-2.5-flash-preview-05-20 (across 3 folds) ---\u001B[0m\n",
      "\u001B[32mINFO:     Reentrant:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 64.39% ± 6.39% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 83.56% ± 4.40% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 72.69% ± 5.70% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 40.67 ± 0.47 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Safe:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 92.72% ± 2.07% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 81.83% ± 3.98% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 86.92% ± 3.13% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 104.67 ± 0.47 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Overall:\u001B[0m\n",
      "\u001B[32mINFO:       Accuracy: 82.32% ± 4.06% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Precision_weighted: 84.80% ± 3.22% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall_weighted: 82.32% ± 4.06% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score_weighted: 82.94% ± 3.83% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "===== PROCESSING MODEL: gemini-2.0-flash =====\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 1 (../explanations/prompting/baseline/cv_1/gemini-2.0-flash) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 1 Overall - Acc: 87.67%, Prec (weighted): 90.25%, Rec (weighted): 87.67%, F1 (weighted): 88.13%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 70.91%, R: 95.12%, F1: 81.25%, Sup: 41\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 97.80%, R: 84.76%, F1: 90.82%, Sup: 105\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 2 (../explanations/prompting/baseline/cv_2/gemini-2.0-flash) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 2 Overall - Acc: 82.88%, Prec (weighted): 85.43%, Rec (weighted): 82.88%, F1 (weighted): 83.48%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 64.81%, R: 85.37%, F1: 73.68%, Sup: 41\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 93.48%, R: 81.90%, F1: 87.31%, Sup: 105\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 3 (../explanations/prompting/baseline/cv_3/gemini-2.0-flash) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 3 Overall - Acc: 82.64%, Prec (weighted): 86.45%, Rec (weighted): 82.64%, F1 (weighted): 83.39%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 63.16%, R: 90.00%, F1: 74.23%, Sup: 40\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 95.40%, R: 79.81%, F1: 86.91%, Sup: 104\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Aggregated Results for Model: gemini-2.0-flash (across 3 folds) ---\u001B[0m\n",
      "\u001B[32mINFO:     Reentrant:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 66.29% ± 3.33% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 90.16% ± 3.98% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 76.39% ± 3.45% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 40.67 ± 0.47 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Safe:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 95.56% ± 1.77% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 82.16% ± 2.03% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 88.35% ± 1.75% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 104.67 ± 0.47 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Overall:\u001B[0m\n",
      "\u001B[32mINFO:       Accuracy: 84.40% ± 2.32% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Precision_weighted: 87.37% ± 2.07% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall_weighted: 84.40% ± 2.32% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score_weighted: 85.00% ± 2.21% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "\n",
      "===== FINAL CROSS-VALIDATION SUMMARY (Overall Weighted Metrics & Accuracy) =====\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "--- Model: gpt-4.1-nano ---\u001B[0m\n",
      "\u001B[32mINFO:   Overall Performance (Accuracy & Weighted Averages):\u001B[0m\n",
      "\u001B[32mINFO:     Accuracy:  72.25% ± 0.47%\u001B[0m\n",
      "\u001B[32mINFO:     Precision (weighted): 61.25% ± 13.47%\u001B[0m\n",
      "\u001B[32mINFO:     Recall (weighted):    72.25% ± 0.47%\u001B[0m\n",
      "\u001B[32mINFO:     F1 Score (weighted):  60.84% ± 0.94%\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "--- Model: o4-mini ---\u001B[0m\n",
      "\u001B[32mINFO:   Overall Performance (Accuracy & Weighted Averages):\u001B[0m\n",
      "\u001B[32mINFO:     Accuracy:  93.11% ± 1.73%\u001B[0m\n",
      "\u001B[32mINFO:     Precision (weighted): 93.63% ± 1.45%\u001B[0m\n",
      "\u001B[32mINFO:     Recall (weighted):    93.11% ± 1.73%\u001B[0m\n",
      "\u001B[32mINFO:     F1 Score (weighted):  92.78% ± 1.92%\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "--- Model: gpt-4.1 ---\u001B[0m\n",
      "\u001B[32mINFO:   Overall Performance (Accuracy & Weighted Averages):\u001B[0m\n",
      "\u001B[32mINFO:     Accuracy:  87.37% ± 1.90%\u001B[0m\n",
      "\u001B[32mINFO:     Precision (weighted): 90.15% ± 1.15%\u001B[0m\n",
      "\u001B[32mINFO:     Recall (weighted):    87.37% ± 1.90%\u001B[0m\n",
      "\u001B[32mINFO:     F1 Score (weighted):  87.86% ± 1.76%\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "--- Model: gpt-4o ---\u001B[0m\n",
      "\u001B[32mINFO:   Overall Performance (Accuracy & Weighted Averages):\u001B[0m\n",
      "\u001B[32mINFO:     Accuracy:  85.08% ± 2.23%\u001B[0m\n",
      "\u001B[32mINFO:     Precision (weighted): 89.13% ± 1.79%\u001B[0m\n",
      "\u001B[32mINFO:     Recall (weighted):    85.08% ± 2.23%\u001B[0m\n",
      "\u001B[32mINFO:     F1 Score (weighted):  85.74% ± 2.10%\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "--- Model: o3-mini ---\u001B[0m\n",
      "\u001B[32mINFO:   Overall Performance (Accuracy & Weighted Averages):\u001B[0m\n",
      "\u001B[32mINFO:     Accuracy:  95.64% ± 0.66%\u001B[0m\n",
      "\u001B[32mINFO:     Precision (weighted): 95.70% ± 0.61%\u001B[0m\n",
      "\u001B[32mINFO:     Recall (weighted):    95.64% ± 0.66%\u001B[0m\n",
      "\u001B[32mINFO:     F1 Score (weighted):  95.57% ± 0.70%\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "--- Model: gpt-4.1-mini ---\u001B[0m\n",
      "\u001B[32mINFO:   Overall Performance (Accuracy & Weighted Averages):\u001B[0m\n",
      "\u001B[32mINFO:     Accuracy:  86.46% ± 1.34%\u001B[0m\n",
      "\u001B[32mINFO:     Precision (weighted): 87.89% ± 1.17%\u001B[0m\n",
      "\u001B[32mINFO:     Recall (weighted):    86.46% ± 1.34%\u001B[0m\n",
      "\u001B[32mINFO:     F1 Score (weighted):  85.07% ± 1.71%\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "--- Model: gemini-1.5-flash ---\u001B[0m\n",
      "\u001B[32mINFO:   Overall Performance (Accuracy & Weighted Averages):\u001B[0m\n",
      "\u001B[32mINFO:     Accuracy:  80.98% ± 2.43%\u001B[0m\n",
      "\u001B[32mINFO:     Precision (weighted): 82.90% ± 3.46%\u001B[0m\n",
      "\u001B[32mINFO:     Recall (weighted):    80.98% ± 2.43%\u001B[0m\n",
      "\u001B[32mINFO:     F1 Score (weighted):  77.74% ± 3.03%\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "--- Model: gemini-2.5-flash-preview-05-20 ---\u001B[0m\n",
      "\u001B[32mINFO:   Overall Performance (Accuracy & Weighted Averages):\u001B[0m\n",
      "\u001B[32mINFO:     Accuracy:  82.32% ± 4.06%\u001B[0m\n",
      "\u001B[32mINFO:     Precision (weighted): 84.80% ± 3.22%\u001B[0m\n",
      "\u001B[32mINFO:     Recall (weighted):    82.32% ± 4.06%\u001B[0m\n",
      "\u001B[32mINFO:     F1 Score (weighted):  82.94% ± 3.83%\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "--- Model: gemini-2.0-flash ---\u001B[0m\n",
      "\u001B[32mINFO:   Overall Performance (Accuracy & Weighted Averages):\u001B[0m\n",
      "\u001B[32mINFO:     Accuracy:  84.40% ± 2.32%\u001B[0m\n",
      "\u001B[32mINFO:     Precision (weighted): 87.37% ± 2.07%\u001B[0m\n",
      "\u001B[32mINFO:     Recall (weighted):    84.40% ± 2.32%\u001B[0m\n",
      "\u001B[32mINFO:     F1 Score (weighted):  85.00% ± 2.21%\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "Saved baseline_classification_weighted_metrics.csv\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "Processing Complete.\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# XRAG Models Evaluation",
   "id": "adaaa17d0af89bad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T06:50:48.183445Z",
     "start_time": "2025-06-12T06:50:46.079945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "# --- Logger Setup ---\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "# --- Utility Functions ---\n",
    "def get_json_files(category_directory):\n",
    "    \"\"\"\n",
    "    Retrieves all 'classification.json' file paths within contract address folders.\n",
    "    Path structure: .../[CATEGORY]/[CONTRACT ADDRESS]/classification.json\n",
    "    \"\"\"\n",
    "    json_files = []\n",
    "    if not os.path.isdir(category_directory):\n",
    "        # This is expected if a category doesn't exist in a fold, so not a warning.\n",
    "        return []\n",
    "\n",
    "    # Iterate through contract address folders\n",
    "    for contract_addr in os.listdir(category_directory):\n",
    "        contract_path = os.path.join(category_directory, contract_addr)\n",
    "        if os.path.isdir(contract_path):\n",
    "            json_file_path = os.path.join(contract_path, \"classification.json\")\n",
    "            if os.path.isfile(json_file_path):\n",
    "                json_files.append(json_file_path)\n",
    "    return json_files\n",
    "\n",
    "\n",
    "def load_json(file_path):\n",
    "    \"\"\"Loads a JSON file and returns its content.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            return json.load(file)\n",
    "    except (json.JSONDecodeError, FileNotFoundError, KeyError) as e:\n",
    "        logger.error(f\"Error processing file '{file_path}': {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# --- Main Script ---\n",
    "# CONFIGURATION\n",
    "# ==============================================================================\n",
    "base_folder = \"../explanations/prompting/rag\"  # Make sure this path is correct\n",
    "num_folds = 3\n",
    "# ==============================================================================\n",
    "\n",
    "# --- 1. Identify Models and Data Types from the first fold ---\n",
    "first_fold_dir = os.path.join(base_folder, \"cv_1\")\n",
    "if not os.path.isdir(first_fold_dir):\n",
    "    logger.error(f\"First fold directory not found: {first_fold_dir}\")\n",
    "    exit()\n",
    "\n",
    "# Get available models from the first fold\n",
    "available_models = [d for d in os.listdir(first_fold_dir) if os.path.isdir(os.path.join(first_fold_dir, d))]\n",
    "if not available_models:\n",
    "    logger.error(f\"No model directories found in {first_fold_dir}\")\n",
    "    exit()\n",
    "logger.info(f\"Found models: {available_models}\")\n",
    "\n",
    "# Get available data types from the first model in the first fold\n",
    "first_model_path = os.path.join(first_fold_dir, available_models[0])\n",
    "available_data_types = [d for d in os.listdir(first_model_path) if os.path.isdir(os.path.join(first_model_path, d))]\n",
    "if not available_data_types:\n",
    "    logger.error(f\"No data type directories found in {first_model_path}\")\n",
    "    exit()\n",
    "logger.info(f\"Found data types: {available_data_types}\")\n",
    "\n",
    "# --- 2. Process each model and data type across all folds ---\n",
    "all_results = {}\n",
    "fold_dirs = [os.path.join(base_folder, f\"cv_{i + 1}\") for i in range(num_folds)]\n",
    "\n",
    "# Define overall metrics to be tracked and averaged\n",
    "overall_metric_keys = [\"Accuracy\", \"Precision_weighted\", \"Recall_weighted\", \"F1 Score_weighted\"]\n",
    "category_metric_keys = [\"Precision\", \"Recall\", \"F1 Score\", \"Support\"]\n",
    "\n",
    "for model_name in available_models:\n",
    "    for data_type in available_data_types:\n",
    "        logger.info(f\"\\n===== PROCESSING MODEL: {model_name} | DATA TYPE: {data_type} =====\")\n",
    "\n",
    "        # Stores metrics for each fold for the current model/data_type\n",
    "        # e.g., model_fold_metrics['overall']['Accuracy'] = [0.9, 0.92, 0.88]\n",
    "        model_fold_metrics = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "        all_true_categories_for_model = set()\n",
    "\n",
    "        for i, fold_dir_path in enumerate(fold_dirs):\n",
    "            fold_num = i + 1\n",
    "            # Construct the path for the specific model and data type within the current fold\n",
    "            data_type_path_in_fold = os.path.join(fold_dir_path, model_name, data_type)\n",
    "\n",
    "            logger.info(f\"\\n  --- Processing Fold {fold_num} ({data_type_path_in_fold}) ---\")\n",
    "\n",
    "            if not os.path.isdir(data_type_path_in_fold):\n",
    "                logger.warning(f\"  Directory not found in this fold, skipping: {data_type_path_in_fold}\")\n",
    "                # Append NaN for all metrics for this fold to keep array lengths consistent\n",
    "                for key in overall_metric_keys:\n",
    "                    model_fold_metrics['overall'][key].append(np.nan)\n",
    "                for cat in [\"reentrant\", \"safe\"]:\n",
    "                    for key in category_metric_keys:\n",
    "                        model_fold_metrics[cat][key].append(np.nan if key != \"Support\" else 0)\n",
    "                continue\n",
    "\n",
    "            y_true_for_fold, y_pred_for_fold = [], []\n",
    "            current_fold_true_categories = set()\n",
    "\n",
    "            # The category directories ('reentrant', 'safe') are inside the data_type path\n",
    "            category_names = [d for d in os.listdir(data_type_path_in_fold) if\n",
    "                              os.path.isdir(os.path.join(data_type_path_in_fold, d))]\n",
    "\n",
    "            for true_category_name in category_names:\n",
    "                true_category_lower = true_category_name.lower()\n",
    "\n",
    "                if true_category_lower not in [\"reentrant\", \"safe\"]:\n",
    "                    logger.warning(f\"    Unexpected category directory '{true_category_name}', skipping.\")\n",
    "                    continue\n",
    "\n",
    "                current_fold_true_categories.add(true_category_lower)\n",
    "                all_true_categories_for_model.add(true_category_lower)\n",
    "\n",
    "                category_path = os.path.join(data_type_path_in_fold, true_category_name)\n",
    "                json_files = get_json_files(category_path)\n",
    "\n",
    "                for file_path in json_files:\n",
    "                    content = load_json(file_path)\n",
    "                    if not content: continue\n",
    "\n",
    "                    predicted_category = content.get(\"classification\", \"unknown\").lower()\n",
    "                    if not predicted_category:\n",
    "                        predicted_category = \"reentrant\"\n",
    "\n",
    "                    y_true_for_fold.append(true_category_lower)\n",
    "                    y_pred_for_fold.append(predicted_category)\n",
    "\n",
    "            if not y_true_for_fold:\n",
    "                logger.warning(f\"  No data collected in fold {fold_num}. Metrics for this fold will be NaN.\")\n",
    "                continue\n",
    "\n",
    "            # --- Calculate metrics for the current fold ---\n",
    "            unique_labels_in_fold = sorted(list(set(y_true_for_fold) | set(y_pred_for_fold)))\n",
    "\n",
    "            # Overall metrics\n",
    "            acc = accuracy_score(y_true_for_fold, y_pred_for_fold)\n",
    "            prec_w = precision_score(y_true_for_fold, y_pred_for_fold, labels=unique_labels_in_fold, average='weighted',\n",
    "                                     zero_division=0)\n",
    "            rec_w = recall_score(y_true_for_fold, y_pred_for_fold, labels=unique_labels_in_fold, average='weighted',\n",
    "                                 zero_division=0)\n",
    "            f1_w = f1_score(y_true_for_fold, y_pred_for_fold, labels=unique_labels_in_fold, average='weighted',\n",
    "                            zero_division=0)\n",
    "\n",
    "            logger.info(\n",
    "                f\"  Fold {fold_num} Overall - Acc: {acc:.2%}, Prec: {prec_w:.2%}, Rec: {rec_w:.2%}, F1: {f1_w:.2%}\")\n",
    "\n",
    "            model_fold_metrics['overall'][\"Accuracy\"].append(acc)\n",
    "            model_fold_metrics['overall'][\"Precision_weighted\"].append(prec_w)\n",
    "            model_fold_metrics['overall'][\"Recall_weighted\"].append(rec_w)\n",
    "            model_fold_metrics['overall'][\"F1 Score_weighted\"].append(f1_w)\n",
    "\n",
    "            # Per-category metrics\n",
    "            for cat_name in sorted(list(current_fold_true_categories)):\n",
    "                prec = precision_score(y_true_for_fold, y_pred_for_fold, labels=unique_labels_in_fold,\n",
    "                                       pos_label=cat_name, average='binary', zero_division=0)\n",
    "                rec = recall_score(y_true_for_fold, y_pred_for_fold, labels=unique_labels_in_fold, pos_label=cat_name,\n",
    "                                   average='binary', zero_division=0)\n",
    "                f1 = f1_score(y_true_for_fold, y_pred_for_fold, labels=unique_labels_in_fold, pos_label=cat_name,\n",
    "                              average='binary', zero_division=0)\n",
    "                support = y_true_for_fold.count(cat_name)\n",
    "\n",
    "                logger.info(f\"    Cat '{cat_name}': P: {prec:.2%}, R: {rec:.2%}, F1: {f1:.2%}, Sup: {support}\")\n",
    "\n",
    "                model_fold_metrics[cat_name][\"Precision\"].append(prec)\n",
    "                model_fold_metrics[cat_name][\"Recall\"].append(rec)\n",
    "                model_fold_metrics[cat_name][\"F1 Score\"].append(f1)\n",
    "                model_fold_metrics[cat_name][\"Support\"].append(support)\n",
    "\n",
    "        # --- 3. Aggregate results for the current model and data type ---\n",
    "        logger.info(f\"\\n  --- Aggregated Results for {model_name} on {data_type} (across {num_folds} folds) ---\")\n",
    "        model_summary = {}\n",
    "\n",
    "        # Ensure all expected categories ('safe', 'reentrant') are processed, even if absent in some folds\n",
    "        expected_categories_for_model = sorted(list(all_true_categories_for_model | {\"safe\", \"reentrant\"}))\n",
    "\n",
    "        for key_to_summarize in ['overall'] + expected_categories_for_model:\n",
    "            summary_metrics = {}\n",
    "            is_overall = (key_to_summarize == 'overall')\n",
    "\n",
    "            metric_keys = overall_metric_keys if is_overall else category_metric_keys\n",
    "            logger.info(f\"    {key_to_summarize.capitalize()}:\")\n",
    "\n",
    "            for metric_name in metric_keys:\n",
    "                values = model_fold_metrics[key_to_summarize].get(metric_name, [])\n",
    "\n",
    "                # Pad with NaN/0 if a fold was skipped or a category was missing\n",
    "                while len(values) < num_folds:\n",
    "                    values.append(np.nan if metric_name != \"Support\" else 0)\n",
    "\n",
    "                valid_values = [v for v in values if not np.isnan(v)]\n",
    "                num_valid_folds = len(valid_values)\n",
    "\n",
    "                if num_valid_folds > 0:\n",
    "                    mean_val = np.mean(valid_values)\n",
    "                    std_dev = np.std(valid_values) if num_valid_folds > 1 else 0.0\n",
    "                    summary_metrics[f\"{metric_name}_mean\"] = mean_val\n",
    "                    summary_metrics[f\"{metric_name}_std\"] = std_dev\n",
    "\n",
    "                    log_msg = f\"      {metric_name}: {mean_val:.2%}\"\n",
    "                    if metric_name != \"Support\":\n",
    "                        log_msg += f\" ± {std_dev:.2%}\"\n",
    "                    else:  # Support doesn't need percentage\n",
    "                        log_msg = f\"      {metric_name}: {mean_val:.2f} ± {std_dev:.2f}\"\n",
    "\n",
    "                    logger.info(f\"{log_msg} (from {num_valid_folds}/{num_folds} folds)\")\n",
    "                else:\n",
    "                    summary_metrics[f\"{metric_name}_mean\"] = np.nan\n",
    "                    summary_metrics[f\"{metric_name}_std\"] = np.nan\n",
    "                    logger.info(f\"      {metric_name}: N/A (No valid data across folds)\")\n",
    "\n",
    "            model_summary[key_to_summarize] = summary_metrics\n",
    "\n",
    "        # Store the complete summary for this model-datatype combo\n",
    "        all_results[f\"{model_name}__{data_type}\"] = model_summary\n",
    "\n",
    "# --- 4. Print Final Summary Table ---\n",
    "logger.info(\"\\n\\n\" + \"=\" * 80)\n",
    "logger.info(\"FINAL CROSS-VALIDATION SUMMARY (Overall Weighted Metrics & Accuracy)\")\n",
    "logger.info(\"=\" * 80)\n",
    "\n",
    "for result_key, summary_data in all_results.items():\n",
    "    logger.info(f\"\\n--- Results for: {result_key} ---\")\n",
    "\n",
    "    if 'overall' in summary_data and summary_data['overall']:\n",
    "        overall_metrics = summary_data['overall']\n",
    "        logger.info(\"  Overall Performance (Accuracy & Weighted Averages):\")\n",
    "        logger.info(\n",
    "            f\"    Accuracy:             {overall_metrics.get('Accuracy_mean', np.nan):.2%} ± {overall_metrics.get('Accuracy_std', np.nan):.2%}\")\n",
    "        logger.info(\n",
    "            f\"    Precision (weighted): {overall_metrics.get('Precision_weighted_mean', np.nan):.2%} ± {overall_metrics.get('Precision_weighted_std', np.nan):.2%}\")\n",
    "        logger.info(\n",
    "            f\"    Recall (weighted):    {overall_metrics.get('Recall_weighted_mean', np.nan):.2%} ± {overall_metrics.get('Recall_weighted_std', np.nan):.2%}\")\n",
    "        logger.info(\n",
    "            f\"    F1 Score (weighted):  {overall_metrics.get('F1 Score_weighted_mean', np.nan):.2%} ± {overall_metrics.get('F1 Score_weighted_std', np.nan):.2%}\")\n",
    "    else:\n",
    "        logger.info(f\"  No overall metrics summary available for {result_key}.\")\n",
    "\n",
    "logger.info(\"\\n\\nProcessing Complete.\")"
   ],
   "id": "6f08684bbf94885e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mINFO: Found models: ['gpt-4.1-nano', 'o4-mini', 'gpt-4.1', 'gpt-4o', 'o3-mini', 'gpt-4.1-mini', 'gemini-2.5-flash-preview-05-20']\u001B[0m\n",
      "\u001B[32mINFO: Found data types: ['ast_cfg', 'cfg', 'ast']\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "===== PROCESSING MODEL: gpt-4.1-nano | DATA TYPE: ast_cfg =====\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 1 (../explanations/prompting/rag/cv_1/gpt-4.1-nano/ast_cfg) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 1 Overall - Acc: 73.29%, Prec: 73.73%, Rec: 73.29%, F1: 64.31%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 75.00%, R: 7.32%, F1: 13.33%, Sup: 41\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 73.24%, R: 99.05%, F1: 84.21%, Sup: 105\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 2 (../explanations/prompting/rag/cv_2/gpt-4.1-nano/ast_cfg) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 2 Overall - Acc: 74.66%, Prec: 81.26%, Rec: 74.66%, F1: 66.14%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 100.00%, R: 9.76%, F1: 17.78%, Sup: 41\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 73.94%, R: 100.00%, F1: 85.02%, Sup: 105\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 3 (../explanations/prompting/rag/cv_3/gpt-4.1-nano/ast_cfg) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 3 Overall - Acc: 73.61%, Prec: 70.56%, Rec: 73.61%, F1: 67.36%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 60.00%, R: 15.00%, F1: 24.00%, Sup: 40\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 74.63%, R: 96.15%, F1: 84.03%, Sup: 104\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Aggregated Results for gpt-4.1-nano on ast_cfg (across 3 folds) ---\u001B[0m\n",
      "\u001B[32mINFO:     Overall:\u001B[0m\n",
      "\u001B[32mINFO:       Accuracy: 73.85% ± 0.58% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Precision_weighted: 75.19% ± 4.49% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall_weighted: 73.85% ± 0.58% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score_weighted: 65.93% ± 1.25% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Reentrant:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 78.33% ± 16.50% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 10.69% ± 3.21% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 18.37% ± 4.37% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 40.67 ± 0.47 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Safe:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 73.94% ± 0.57% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 98.40% ± 1.64% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 84.42% ± 0.43% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 104.67 ± 0.47 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "===== PROCESSING MODEL: gpt-4.1-nano | DATA TYPE: cfg =====\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 1 (../explanations/prompting/rag/cv_1/gpt-4.1-nano/cfg) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 1 Overall - Acc: 82.19%, Prec: 84.41%, Rec: 82.19%, F1: 79.42%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 94.12%, R: 39.02%, F1: 55.17%, Sup: 41\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 80.62%, R: 99.05%, F1: 88.89%, Sup: 105\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 2 (../explanations/prompting/rag/cv_2/gpt-4.1-nano/cfg) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 2 Overall - Acc: 81.51%, Prec: 81.55%, Rec: 81.51%, F1: 79.49%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 81.82%, R: 43.90%, F1: 57.14%, Sup: 41\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 81.45%, R: 96.19%, F1: 88.21%, Sup: 105\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 3 (../explanations/prompting/rag/cv_3/gpt-4.1-nano/cfg) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 3 Overall - Acc: 79.86%, Prec: 80.31%, Rec: 79.86%, F1: 76.80%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 82.35%, R: 35.00%, F1: 49.12%, Sup: 40\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 79.53%, R: 97.12%, F1: 87.45%, Sup: 104\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Aggregated Results for gpt-4.1-nano on cfg (across 3 folds) ---\u001B[0m\n",
      "\u001B[32mINFO:     Overall:\u001B[0m\n",
      "\u001B[32mINFO:       Accuracy: 81.19% ± 0.98% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Precision_weighted: 82.09% ± 1.72% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall_weighted: 81.19% ± 0.98% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score_weighted: 78.57% ± 1.25% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Reentrant:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 86.10% ± 5.68% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 39.31% ± 3.64% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 53.81% ± 3.41% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 40.67 ± 0.47 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Safe:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 80.53% ± 0.79% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 97.45% ± 1.19% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 88.18% ± 0.59% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 104.67 ± 0.47 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "===== PROCESSING MODEL: gpt-4.1-nano | DATA TYPE: ast =====\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 1 (../explanations/prompting/rag/cv_1/gpt-4.1-nano/ast) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 1 Overall - Acc: 72.60%, Prec: 71.03%, Rec: 72.60%, F1: 62.87%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 66.67%, R: 4.88%, F1: 9.09%, Sup: 41\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 72.73%, R: 99.05%, F1: 83.87%, Sup: 105\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 2 (../explanations/prompting/rag/cv_2/gpt-4.1-nano/ast) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 2 Overall - Acc: 76.03%, Prec: 82.02%, Rec: 76.03%, F1: 68.81%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 100.00%, R: 14.63%, F1: 25.53%, Sup: 41\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 75.00%, R: 100.00%, F1: 85.71%, Sup: 105\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 3 (../explanations/prompting/rag/cv_3/gpt-4.1-nano/ast) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 3 Overall - Acc: 70.83%, Prec: 65.24%, Rec: 70.83%, F1: 65.43%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 42.86%, R: 15.00%, F1: 22.22%, Sup: 40\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 73.85%, R: 92.31%, F1: 82.05%, Sup: 104\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Aggregated Results for gpt-4.1-nano on ast (across 3 folds) ---\u001B[0m\n",
      "\u001B[32mINFO:     Overall:\u001B[0m\n",
      "\u001B[32mINFO:       Accuracy: 73.15% ± 2.16% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Precision_weighted: 72.76% ± 6.96% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall_weighted: 73.15% ± 2.16% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score_weighted: 65.71% ± 2.43% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Reentrant:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 69.84% ± 23.44% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 11.50% ± 4.69% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 18.95% ± 7.10% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 40.67 ± 0.47 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Safe:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 73.86% ± 0.93% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 97.12% ± 3.42% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 83.88% ± 1.50% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 104.67 ± 0.47 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "===== PROCESSING MODEL: o4-mini | DATA TYPE: ast_cfg =====\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 1 (../explanations/prompting/rag/cv_1/o4-mini/ast_cfg) ---\u001B[0m\n",
      "\u001B[33mWARNING:   Directory not found in this fold, skipping: ../explanations/prompting/rag/cv_1/o4-mini/ast_cfg\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 2 (../explanations/prompting/rag/cv_2/o4-mini/ast_cfg) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 2 Overall - Acc: 96.58%, Prec: 96.60%, Rec: 96.58%, F1: 96.53%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 97.37%, R: 90.24%, F1: 93.67%, Sup: 41\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 96.30%, R: 99.05%, F1: 97.65%, Sup: 105\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 3 (../explanations/prompting/rag/cv_3/o4-mini/ast_cfg) ---\u001B[0m\n",
      "\u001B[33mWARNING:   Directory not found in this fold, skipping: ../explanations/prompting/rag/cv_3/o4-mini/ast_cfg\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Aggregated Results for o4-mini on ast_cfg (across 3 folds) ---\u001B[0m\n",
      "\u001B[32mINFO:     Overall:\u001B[0m\n",
      "\u001B[32mINFO:       Accuracy: 96.58% ± 0.00% (from 1/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Precision_weighted: 96.60% ± 0.00% (from 1/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall_weighted: 96.58% ± 0.00% (from 1/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score_weighted: 96.53% ± 0.00% (from 1/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Reentrant:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 97.37% ± 0.00% (from 1/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 90.24% ± 0.00% (from 1/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 93.67% ± 0.00% (from 1/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 13.67 ± 19.33 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Safe:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 96.30% ± 0.00% (from 1/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 99.05% ± 0.00% (from 1/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 97.65% ± 0.00% (from 1/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 35.00 ± 49.50 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "===== PROCESSING MODEL: o4-mini | DATA TYPE: cfg =====\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 1 (../explanations/prompting/rag/cv_1/o4-mini/cfg) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 1 Overall - Acc: 93.15%, Prec: 93.15%, Rec: 93.15%, F1: 93.15%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 87.80%, R: 87.80%, F1: 87.80%, Sup: 41\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 95.24%, R: 95.24%, F1: 95.24%, Sup: 105\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 2 (../explanations/prompting/rag/cv_2/o4-mini/cfg) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 2 Overall - Acc: 97.26%, Prec: 97.36%, Rec: 97.26%, F1: 97.22%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 100.00%, R: 90.24%, F1: 94.87%, Sup: 41\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 96.33%, R: 100.00%, F1: 98.13%, Sup: 105\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 3 (../explanations/prompting/rag/cv_3/o4-mini/cfg) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 3 Overall - Acc: 92.36%, Prec: 92.71%, Rec: 92.36%, F1: 92.04%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 96.77%, R: 75.00%, F1: 84.51%, Sup: 40\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 91.15%, R: 99.04%, F1: 94.93%, Sup: 104\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Aggregated Results for o4-mini on cfg (across 3 folds) ---\u001B[0m\n",
      "\u001B[32mINFO:     Overall:\u001B[0m\n",
      "\u001B[32mINFO:       Accuracy: 94.26% ± 2.15% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Precision_weighted: 94.41% ± 2.10% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall_weighted: 94.26% ± 2.15% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score_weighted: 94.13% ± 2.23% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Reentrant:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 94.86% ± 5.16% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 84.35% ± 6.69% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 89.06% ± 4.32% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 40.67 ± 0.47 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Safe:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 94.24% ± 2.23% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 98.09% ± 2.06% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 96.10% ± 1.44% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 104.67 ± 0.47 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "===== PROCESSING MODEL: o4-mini | DATA TYPE: ast =====\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 1 (../explanations/prompting/rag/cv_1/o4-mini/ast) ---\u001B[0m\n",
      "\u001B[33mWARNING:   Directory not found in this fold, skipping: ../explanations/prompting/rag/cv_1/o4-mini/ast\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 2 (../explanations/prompting/rag/cv_2/o4-mini/ast) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 2 Overall - Acc: 95.21%, Prec: 95.19%, Rec: 95.21%, F1: 95.15%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 94.74%, R: 87.80%, F1: 91.14%, Sup: 41\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 95.37%, R: 98.10%, F1: 96.71%, Sup: 105\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 3 (../explanations/prompting/rag/cv_3/o4-mini/ast) ---\u001B[0m\n",
      "\u001B[33mWARNING:   Directory not found in this fold, skipping: ../explanations/prompting/rag/cv_3/o4-mini/ast\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Aggregated Results for o4-mini on ast (across 3 folds) ---\u001B[0m\n",
      "\u001B[32mINFO:     Overall:\u001B[0m\n",
      "\u001B[32mINFO:       Accuracy: 95.21% ± 0.00% (from 1/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Precision_weighted: 95.19% ± 0.00% (from 1/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall_weighted: 95.21% ± 0.00% (from 1/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score_weighted: 95.15% ± 0.00% (from 1/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Reentrant:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 94.74% ± 0.00% (from 1/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 87.80% ± 0.00% (from 1/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 91.14% ± 0.00% (from 1/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 13.67 ± 19.33 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Safe:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 95.37% ± 0.00% (from 1/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 98.10% ± 0.00% (from 1/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 96.71% ± 0.00% (from 1/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 35.00 ± 49.50 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "===== PROCESSING MODEL: gpt-4.1 | DATA TYPE: ast_cfg =====\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 1 (../explanations/prompting/rag/cv_1/gpt-4.1/ast_cfg) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 1 Overall - Acc: 91.78%, Prec: 92.79%, Rec: 91.78%, F1: 91.98%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 79.59%, R: 95.12%, F1: 86.67%, Sup: 41\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 97.94%, R: 90.48%, F1: 94.06%, Sup: 105\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 2 (../explanations/prompting/rag/cv_2/gpt-4.1/ast_cfg) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 2 Overall - Acc: 94.52%, Prec: 94.52%, Rec: 94.52%, F1: 94.52%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 90.24%, R: 90.24%, F1: 90.24%, Sup: 41\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 96.19%, R: 96.19%, F1: 96.19%, Sup: 105\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 3 (../explanations/prompting/rag/cv_3/gpt-4.1/ast_cfg) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 3 Overall - Acc: 86.81%, Prec: 87.49%, Rec: 86.81%, F1: 87.03%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 73.33%, R: 82.50%, F1: 77.65%, Sup: 40\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 92.93%, R: 88.46%, F1: 90.64%, Sup: 104\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Aggregated Results for gpt-4.1 on ast_cfg (across 3 folds) ---\u001B[0m\n",
      "\u001B[32mINFO:     Overall:\u001B[0m\n",
      "\u001B[32mINFO:       Accuracy: 91.04% ± 3.19% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Precision_weighted: 91.60% ± 2.99% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall_weighted: 91.04% ± 3.19% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score_weighted: 91.18% ± 3.11% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Reentrant:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 81.06% ± 6.98% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 89.29% ± 5.20% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 84.85% ± 5.30% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 40.67 ± 0.47 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Safe:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 95.69% ± 2.08% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 91.71% ± 3.27% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 93.63% ± 2.29% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 104.67 ± 0.47 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "===== PROCESSING MODEL: gpt-4.1 | DATA TYPE: cfg =====\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 1 (../explanations/prompting/rag/cv_1/gpt-4.1/cfg) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 1 Overall - Acc: 89.73%, Prec: 91.01%, Rec: 89.73%, F1: 90.00%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 76.00%, R: 92.68%, F1: 83.52%, Sup: 41\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 96.88%, R: 88.57%, F1: 92.54%, Sup: 105\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 2 (../explanations/prompting/rag/cv_2/gpt-4.1/cfg) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 2 Overall - Acc: 93.15%, Prec: 93.09%, Rec: 93.15%, F1: 93.10%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 89.74%, R: 85.37%, F1: 87.50%, Sup: 41\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 94.39%, R: 96.19%, F1: 95.28%, Sup: 105\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 3 (../explanations/prompting/rag/cv_3/gpt-4.1/cfg) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 3 Overall - Acc: 93.06%, Prec: 92.99%, Rec: 93.06%, F1: 93.00%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 89.47%, R: 85.00%, F1: 87.18%, Sup: 40\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 94.34%, R: 96.15%, F1: 95.24%, Sup: 104\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Aggregated Results for gpt-4.1 on cfg (across 3 folds) ---\u001B[0m\n",
      "\u001B[32mINFO:     Overall:\u001B[0m\n",
      "\u001B[32mINFO:       Accuracy: 91.98% ± 1.59% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Precision_weighted: 92.36% ± 0.96% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall_weighted: 91.98% ± 1.59% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score_weighted: 92.03% ± 1.44% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Reentrant:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 85.07% ± 6.42% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 87.68% ± 3.54% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 86.07% ± 1.81% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 40.67 ± 0.47 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Safe:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 95.20% ± 1.18% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 93.64% ± 3.58% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 94.35% ± 1.28% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 104.67 ± 0.47 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "===== PROCESSING MODEL: gpt-4.1 | DATA TYPE: ast =====\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 1 (../explanations/prompting/rag/cv_1/gpt-4.1/ast) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 1 Overall - Acc: 93.15%, Prec: 93.77%, Rec: 93.15%, F1: 93.28%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 82.98%, R: 95.12%, F1: 88.64%, Sup: 41\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 97.98%, R: 92.38%, F1: 95.10%, Sup: 105\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 2 (../explanations/prompting/rag/cv_2/gpt-4.1/ast) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 2 Overall - Acc: 94.52%, Prec: 94.52%, Rec: 94.52%, F1: 94.52%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 90.24%, R: 90.24%, F1: 90.24%, Sup: 41\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 96.19%, R: 96.19%, F1: 96.19%, Sup: 105\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 3 (../explanations/prompting/rag/cv_3/gpt-4.1/ast) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 3 Overall - Acc: 87.50%, Prec: 88.00%, Rec: 87.50%, F1: 87.68%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 75.00%, R: 82.50%, F1: 78.57%, Sup: 40\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 93.00%, R: 89.42%, F1: 91.18%, Sup: 104\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Aggregated Results for gpt-4.1 on ast (across 3 folds) ---\u001B[0m\n",
      "\u001B[32mINFO:     Overall:\u001B[0m\n",
      "\u001B[32mINFO:       Accuracy: 91.72% ± 3.04% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Precision_weighted: 92.10% ± 2.91% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall_weighted: 91.72% ± 3.04% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score_weighted: 91.83% ± 2.98% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Reentrant:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 82.74% ± 6.23% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 89.29% ± 5.20% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 85.82% ± 5.17% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 40.67 ± 0.47 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Safe:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 95.72% ± 2.06% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 92.66% ± 2.77% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 94.15% ± 2.15% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 104.67 ± 0.47 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "===== PROCESSING MODEL: gpt-4o | DATA TYPE: ast_cfg =====\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 1 (../explanations/prompting/rag/cv_1/gpt-4o/ast_cfg) ---\u001B[0m\n",
      "\u001B[33mWARNING:   Directory not found in this fold, skipping: ../explanations/prompting/rag/cv_1/gpt-4o/ast_cfg\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 2 (../explanations/prompting/rag/cv_2/gpt-4o/ast_cfg) ---\u001B[0m\n",
      "\u001B[33mWARNING:   Directory not found in this fold, skipping: ../explanations/prompting/rag/cv_2/gpt-4o/ast_cfg\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 3 (../explanations/prompting/rag/cv_3/gpt-4o/ast_cfg) ---\u001B[0m\n",
      "\u001B[33mWARNING:   Directory not found in this fold, skipping: ../explanations/prompting/rag/cv_3/gpt-4o/ast_cfg\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Aggregated Results for gpt-4o on ast_cfg (across 3 folds) ---\u001B[0m\n",
      "\u001B[32mINFO:     Overall:\u001B[0m\n",
      "\u001B[32mINFO:       Accuracy: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       Precision_weighted: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall_weighted: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score_weighted: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:     Reentrant:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 0.00 ± 0.00 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Safe:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 0.00 ± 0.00 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "===== PROCESSING MODEL: gpt-4o | DATA TYPE: cfg =====\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 1 (../explanations/prompting/rag/cv_1/gpt-4o/cfg) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 1 Overall - Acc: 91.78%, Prec: 92.79%, Rec: 91.78%, F1: 91.98%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 79.59%, R: 95.12%, F1: 86.67%, Sup: 41\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 97.94%, R: 90.48%, F1: 94.06%, Sup: 105\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 2 (../explanations/prompting/rag/cv_2/gpt-4o/cfg) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 2 Overall - Acc: 90.41%, Prec: 90.82%, Rec: 90.41%, F1: 90.54%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 80.00%, R: 87.80%, F1: 83.72%, Sup: 41\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 95.05%, R: 91.43%, F1: 93.20%, Sup: 105\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 3 (../explanations/prompting/rag/cv_3/gpt-4o/cfg) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 3 Overall - Acc: 93.75%, Prec: 93.71%, Rec: 93.75%, F1: 93.73%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 89.74%, R: 87.50%, F1: 88.61%, Sup: 40\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 95.24%, R: 96.15%, F1: 95.69%, Sup: 104\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Aggregated Results for gpt-4o on cfg (across 3 folds) ---\u001B[0m\n",
      "\u001B[32mINFO:     Overall:\u001B[0m\n",
      "\u001B[32mINFO:       Accuracy: 91.98% ± 1.37% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Precision_weighted: 92.44% ± 1.20% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall_weighted: 91.98% ± 1.37% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score_weighted: 92.08% ± 1.30% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Reentrant:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 83.11% ± 4.69% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 90.14% ± 3.52% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 86.33% ± 2.01% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 40.67 ± 0.47 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Safe:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 96.08% ± 1.32% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 92.69% ± 2.48% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 94.32% ± 1.03% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 104.67 ± 0.47 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "===== PROCESSING MODEL: gpt-4o | DATA TYPE: ast =====\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 1 (../explanations/prompting/rag/cv_1/gpt-4o/ast) ---\u001B[0m\n",
      "\u001B[33mWARNING:   Directory not found in this fold, skipping: ../explanations/prompting/rag/cv_1/gpt-4o/ast\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 2 (../explanations/prompting/rag/cv_2/gpt-4o/ast) ---\u001B[0m\n",
      "\u001B[33mWARNING:   Directory not found in this fold, skipping: ../explanations/prompting/rag/cv_2/gpt-4o/ast\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 3 (../explanations/prompting/rag/cv_3/gpt-4o/ast) ---\u001B[0m\n",
      "\u001B[33mWARNING:   Directory not found in this fold, skipping: ../explanations/prompting/rag/cv_3/gpt-4o/ast\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Aggregated Results for gpt-4o on ast (across 3 folds) ---\u001B[0m\n",
      "\u001B[32mINFO:     Overall:\u001B[0m\n",
      "\u001B[32mINFO:       Accuracy: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       Precision_weighted: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall_weighted: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score_weighted: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:     Reentrant:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 0.00 ± 0.00 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Safe:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 0.00 ± 0.00 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "===== PROCESSING MODEL: o3-mini | DATA TYPE: ast_cfg =====\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 1 (../explanations/prompting/rag/cv_1/o3-mini/ast_cfg) ---\u001B[0m\n",
      "\u001B[33mWARNING:   Directory not found in this fold, skipping: ../explanations/prompting/rag/cv_1/o3-mini/ast_cfg\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 2 (../explanations/prompting/rag/cv_2/o3-mini/ast_cfg) ---\u001B[0m\n",
      "\u001B[33mWARNING:   Directory not found in this fold, skipping: ../explanations/prompting/rag/cv_2/o3-mini/ast_cfg\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 3 (../explanations/prompting/rag/cv_3/o3-mini/ast_cfg) ---\u001B[0m\n",
      "\u001B[33mWARNING:   Directory not found in this fold, skipping: ../explanations/prompting/rag/cv_3/o3-mini/ast_cfg\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Aggregated Results for o3-mini on ast_cfg (across 3 folds) ---\u001B[0m\n",
      "\u001B[32mINFO:     Overall:\u001B[0m\n",
      "\u001B[32mINFO:       Accuracy: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       Precision_weighted: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall_weighted: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score_weighted: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:     Reentrant:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 0.00 ± 0.00 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Safe:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 0.00 ± 0.00 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "===== PROCESSING MODEL: o3-mini | DATA TYPE: cfg =====\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 1 (../explanations/prompting/rag/cv_1/o3-mini/cfg) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 1 Overall - Acc: 97.26%, Prec: 97.34%, Rec: 97.26%, F1: 97.28%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 93.02%, R: 97.56%, F1: 95.24%, Sup: 41\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 99.03%, R: 97.14%, F1: 98.08%, Sup: 105\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 2 (../explanations/prompting/rag/cv_2/o3-mini/cfg) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 2 Overall - Acc: 96.58%, Prec: 96.73%, Rec: 96.58%, F1: 96.50%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 100.00%, R: 87.80%, F1: 93.51%, Sup: 41\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 95.45%, R: 100.00%, F1: 97.67%, Sup: 105\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 3 (../explanations/prompting/rag/cv_3/o3-mini/cfg) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 3 Overall - Acc: 95.83%, Prec: 95.83%, Rec: 95.83%, F1: 95.83%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 92.50%, R: 92.50%, F1: 92.50%, Sup: 40\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 97.12%, R: 97.12%, F1: 97.12%, Sup: 104\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Aggregated Results for o3-mini on cfg (across 3 folds) ---\u001B[0m\n",
      "\u001B[32mINFO:     Overall:\u001B[0m\n",
      "\u001B[32mINFO:       Accuracy: 96.56% ± 0.58% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Precision_weighted: 96.64% ± 0.62% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall_weighted: 96.56% ± 0.58% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score_weighted: 96.54% ± 0.59% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Reentrant:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 95.17% ± 3.42% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 92.62% ± 3.98% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 93.75% ± 1.13% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 40.67 ± 0.47 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Safe:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 97.20% ± 1.46% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 98.09% ± 1.35% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 97.62% ± 0.39% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 104.67 ± 0.47 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "===== PROCESSING MODEL: o3-mini | DATA TYPE: ast =====\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 1 (../explanations/prompting/rag/cv_1/o3-mini/ast) ---\u001B[0m\n",
      "\u001B[33mWARNING:   Directory not found in this fold, skipping: ../explanations/prompting/rag/cv_1/o3-mini/ast\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 2 (../explanations/prompting/rag/cv_2/o3-mini/ast) ---\u001B[0m\n",
      "\u001B[33mWARNING:   Directory not found in this fold, skipping: ../explanations/prompting/rag/cv_2/o3-mini/ast\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 3 (../explanations/prompting/rag/cv_3/o3-mini/ast) ---\u001B[0m\n",
      "\u001B[33mWARNING:   Directory not found in this fold, skipping: ../explanations/prompting/rag/cv_3/o3-mini/ast\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Aggregated Results for o3-mini on ast (across 3 folds) ---\u001B[0m\n",
      "\u001B[32mINFO:     Overall:\u001B[0m\n",
      "\u001B[32mINFO:       Accuracy: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       Precision_weighted: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall_weighted: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score_weighted: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:     Reentrant:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 0.00 ± 0.00 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Safe:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 0.00 ± 0.00 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "===== PROCESSING MODEL: gpt-4.1-mini | DATA TYPE: ast_cfg =====\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 1 (../explanations/prompting/rag/cv_1/gpt-4.1-mini/ast_cfg) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 1 Overall - Acc: 84.93%, Prec: 86.58%, Rec: 84.93%, F1: 83.16%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 95.24%, R: 48.78%, F1: 64.52%, Sup: 41\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 83.20%, R: 99.05%, F1: 90.43%, Sup: 105\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 2 (../explanations/prompting/rag/cv_2/gpt-4.1-mini/ast_cfg) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 2 Overall - Acc: 85.62%, Prec: 88.01%, Rec: 85.62%, F1: 83.79%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 100.00%, R: 48.78%, F1: 65.57%, Sup: 41\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 83.33%, R: 100.00%, F1: 90.91%, Sup: 105\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 3 (../explanations/prompting/rag/cv_3/gpt-4.1-mini/ast_cfg) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 3 Overall - Acc: 84.72%, Prec: 84.31%, Rec: 84.72%, F1: 83.98%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 80.00%, R: 60.00%, F1: 68.57%, Sup: 40\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 85.96%, R: 94.23%, F1: 89.91%, Sup: 104\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Aggregated Results for gpt-4.1-mini on ast_cfg (across 3 folds) ---\u001B[0m\n",
      "\u001B[32mINFO:     Overall:\u001B[0m\n",
      "\u001B[32mINFO:       Accuracy: 85.09% ± 0.38% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Precision_weighted: 86.30% ± 1.53% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall_weighted: 85.09% ± 0.38% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score_weighted: 83.64% ± 0.35% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Reentrant:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 91.75% ± 8.53% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 52.52% ± 5.29% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 66.22% ± 1.72% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 40.67 ± 0.47 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Safe:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 84.17% ± 1.27% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 97.76% ± 2.53% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 90.42% ± 0.41% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 104.67 ± 0.47 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "===== PROCESSING MODEL: gpt-4.1-mini | DATA TYPE: cfg =====\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 1 (../explanations/prompting/rag/cv_1/gpt-4.1-mini/cfg) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 1 Overall - Acc: 87.67%, Prec: 88.15%, Rec: 87.67%, F1: 87.84%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 75.56%, R: 82.93%, F1: 79.07%, Sup: 41\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 93.07%, R: 89.52%, F1: 91.26%, Sup: 105\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 2 (../explanations/prompting/rag/cv_2/gpt-4.1-mini/cfg) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 2 Overall - Acc: 89.73%, Prec: 89.57%, Rec: 89.73%, F1: 89.60%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 84.21%, R: 78.05%, F1: 81.01%, Sup: 41\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 91.67%, R: 94.29%, F1: 92.96%, Sup: 105\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 3 (../explanations/prompting/rag/cv_3/gpt-4.1-mini/cfg) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 3 Overall - Acc: 87.50%, Prec: 87.28%, Rec: 87.50%, F1: 87.04%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 84.38%, R: 67.50%, F1: 75.00%, Sup: 40\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 88.39%, R: 95.19%, F1: 91.67%, Sup: 104\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Aggregated Results for gpt-4.1-mini on cfg (across 3 folds) ---\u001B[0m\n",
      "\u001B[32mINFO:     Overall:\u001B[0m\n",
      "\u001B[32mINFO:       Accuracy: 88.30% ± 1.01% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Precision_weighted: 88.33% ± 0.95% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall_weighted: 88.30% ± 1.01% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score_weighted: 88.16% ± 1.07% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Reentrant:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 81.38% ± 4.12% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 76.16% ± 6.44% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 78.36% ± 2.51% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 40.67 ± 0.47 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Safe:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 91.04% ± 1.96% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 93.00% ± 2.49% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 91.96% ± 0.72% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 104.67 ± 0.47 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "===== PROCESSING MODEL: gpt-4.1-mini | DATA TYPE: ast =====\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 1 (../explanations/prompting/rag/cv_1/gpt-4.1-mini/ast) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 1 Overall - Acc: 86.30%, Prec: 87.67%, Rec: 86.30%, F1: 84.92%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 95.65%, R: 53.66%, F1: 68.75%, Sup: 41\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 84.55%, R: 99.05%, F1: 91.23%, Sup: 105\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 2 (../explanations/prompting/rag/cv_2/gpt-4.1-mini/ast) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 2 Overall - Acc: 83.56%, Prec: 85.50%, Rec: 83.56%, F1: 81.33%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 94.74%, R: 43.90%, F1: 60.00%, Sup: 41\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 81.89%, R: 99.05%, F1: 89.66%, Sup: 105\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 3 (../explanations/prompting/rag/cv_3/gpt-4.1-mini/ast) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 3 Overall - Acc: 84.72%, Prec: 84.72%, Rec: 84.72%, F1: 84.72%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 72.50%, R: 72.50%, F1: 72.50%, Sup: 40\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 89.42%, R: 89.42%, F1: 89.42%, Sup: 104\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Aggregated Results for gpt-4.1-mini on ast (across 3 folds) ---\u001B[0m\n",
      "\u001B[32mINFO:     Overall:\u001B[0m\n",
      "\u001B[32mINFO:       Accuracy: 84.86% ± 1.12% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Precision_weighted: 85.96% ± 1.25% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall_weighted: 84.86% ± 1.12% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score_weighted: 83.66% ± 1.65% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Reentrant:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 87.63% ± 10.70% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 56.69% ± 11.87% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 67.08% ± 5.24% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 40.67 ± 0.47 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Safe:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 85.29% ± 3.12% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 95.84% ± 4.54% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 90.10% ± 0.80% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 104.67 ± 0.47 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "===== PROCESSING MODEL: gemini-2.5-flash-preview-05-20 | DATA TYPE: ast_cfg =====\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 1 (../explanations/prompting/rag/cv_1/gemini-2.5-flash-preview-05-20/ast_cfg) ---\u001B[0m\n",
      "\u001B[33mWARNING:   Directory not found in this fold, skipping: ../explanations/prompting/rag/cv_1/gemini-2.5-flash-preview-05-20/ast_cfg\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 2 (../explanations/prompting/rag/cv_2/gemini-2.5-flash-preview-05-20/ast_cfg) ---\u001B[0m\n",
      "\u001B[33mWARNING:   Directory not found in this fold, skipping: ../explanations/prompting/rag/cv_2/gemini-2.5-flash-preview-05-20/ast_cfg\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 3 (../explanations/prompting/rag/cv_3/gemini-2.5-flash-preview-05-20/ast_cfg) ---\u001B[0m\n",
      "\u001B[33mWARNING:   Directory not found in this fold, skipping: ../explanations/prompting/rag/cv_3/gemini-2.5-flash-preview-05-20/ast_cfg\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Aggregated Results for gemini-2.5-flash-preview-05-20 on ast_cfg (across 3 folds) ---\u001B[0m\n",
      "\u001B[32mINFO:     Overall:\u001B[0m\n",
      "\u001B[32mINFO:       Accuracy: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       Precision_weighted: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall_weighted: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score_weighted: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:     Reentrant:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 0.00 ± 0.00 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Safe:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 0.00 ± 0.00 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "===== PROCESSING MODEL: gemini-2.5-flash-preview-05-20 | DATA TYPE: cfg =====\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 1 (../explanations/prompting/rag/cv_1/gemini-2.5-flash-preview-05-20/cfg) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 1 Overall - Acc: 83.56%, Prec: 88.88%, Rec: 83.56%, F1: 84.34%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 63.49%, R: 97.56%, F1: 76.92%, Sup: 41\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 98.80%, R: 78.10%, F1: 87.23%, Sup: 105\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 2 (../explanations/prompting/rag/cv_2/gemini-2.5-flash-preview-05-20/cfg) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 2 Overall - Acc: 78.79%, Prec: 100.00%, Rec: 78.79%, F1: 88.14%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 100.00%, R: 78.79%, F1: 88.14%, Sup: 99\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 3 (../explanations/prompting/rag/cv_3/gemini-2.5-flash-preview-05-20/cfg) ---\u001B[0m\n",
      "\u001B[32mINFO:   Fold 3 Overall - Acc: 83.22%, Prec: 89.61%, Rec: 83.22%, F1: 84.10%\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'reentrant': P: 61.90%, R: 100.00%, F1: 76.47%, Sup: 39\u001B[0m\n",
      "\u001B[32mINFO:     Cat 'safe': P: 100.00%, R: 76.92%, F1: 86.96%, Sup: 104\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Aggregated Results for gemini-2.5-flash-preview-05-20 on cfg (across 3 folds) ---\u001B[0m\n",
      "\u001B[32mINFO:     Overall:\u001B[0m\n",
      "\u001B[32mINFO:       Accuracy: 81.86% ± 2.17% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Precision_weighted: 92.83% ± 5.08% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall_weighted: 81.86% ± 2.17% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score_weighted: 85.52% ± 1.85% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Reentrant:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 62.70% ± 0.79% (from 2/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 98.78% ± 1.22% (from 2/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 76.70% ± 0.23% (from 2/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 26.67 ± 18.87 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Safe:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: 99.60% ± 0.57% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: 77.94% ± 0.77% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: 87.44% ± 0.50% (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 102.67 ± 2.62 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "===== PROCESSING MODEL: gemini-2.5-flash-preview-05-20 | DATA TYPE: ast =====\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 1 (../explanations/prompting/rag/cv_1/gemini-2.5-flash-preview-05-20/ast) ---\u001B[0m\n",
      "\u001B[33mWARNING:   Directory not found in this fold, skipping: ../explanations/prompting/rag/cv_1/gemini-2.5-flash-preview-05-20/ast\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 2 (../explanations/prompting/rag/cv_2/gemini-2.5-flash-preview-05-20/ast) ---\u001B[0m\n",
      "\u001B[33mWARNING:   Directory not found in this fold, skipping: ../explanations/prompting/rag/cv_2/gemini-2.5-flash-preview-05-20/ast\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Processing Fold 3 (../explanations/prompting/rag/cv_3/gemini-2.5-flash-preview-05-20/ast) ---\u001B[0m\n",
      "\u001B[33mWARNING:   Directory not found in this fold, skipping: ../explanations/prompting/rag/cv_3/gemini-2.5-flash-preview-05-20/ast\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "  --- Aggregated Results for gemini-2.5-flash-preview-05-20 on ast (across 3 folds) ---\u001B[0m\n",
      "\u001B[32mINFO:     Overall:\u001B[0m\n",
      "\u001B[32mINFO:       Accuracy: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       Precision_weighted: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall_weighted: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score_weighted: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:     Reentrant:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 0.00 ± 0.00 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO:     Safe:\u001B[0m\n",
      "\u001B[32mINFO:       Precision: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       Recall: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       F1 Score: N/A (No valid data across folds)\u001B[0m\n",
      "\u001B[32mINFO:       Support: 0.00 ± 0.00 (from 3/3 folds)\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "\n",
      "================================================================================\u001B[0m\n",
      "\u001B[32mINFO: FINAL CROSS-VALIDATION SUMMARY (Overall Weighted Metrics & Accuracy)\u001B[0m\n",
      "\u001B[32mINFO: ================================================================================\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "--- Results for: gpt-4.1-nano__ast_cfg ---\u001B[0m\n",
      "\u001B[32mINFO:   Overall Performance (Accuracy & Weighted Averages):\u001B[0m\n",
      "\u001B[32mINFO:     Accuracy:             73.85% ± 0.58%\u001B[0m\n",
      "\u001B[32mINFO:     Precision (weighted): 75.19% ± 4.49%\u001B[0m\n",
      "\u001B[32mINFO:     Recall (weighted):    73.85% ± 0.58%\u001B[0m\n",
      "\u001B[32mINFO:     F1 Score (weighted):  65.93% ± 1.25%\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "--- Results for: gpt-4.1-nano__cfg ---\u001B[0m\n",
      "\u001B[32mINFO:   Overall Performance (Accuracy & Weighted Averages):\u001B[0m\n",
      "\u001B[32mINFO:     Accuracy:             81.19% ± 0.98%\u001B[0m\n",
      "\u001B[32mINFO:     Precision (weighted): 82.09% ± 1.72%\u001B[0m\n",
      "\u001B[32mINFO:     Recall (weighted):    81.19% ± 0.98%\u001B[0m\n",
      "\u001B[32mINFO:     F1 Score (weighted):  78.57% ± 1.25%\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "--- Results for: gpt-4.1-nano__ast ---\u001B[0m\n",
      "\u001B[32mINFO:   Overall Performance (Accuracy & Weighted Averages):\u001B[0m\n",
      "\u001B[32mINFO:     Accuracy:             73.15% ± 2.16%\u001B[0m\n",
      "\u001B[32mINFO:     Precision (weighted): 72.76% ± 6.96%\u001B[0m\n",
      "\u001B[32mINFO:     Recall (weighted):    73.15% ± 2.16%\u001B[0m\n",
      "\u001B[32mINFO:     F1 Score (weighted):  65.71% ± 2.43%\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "--- Results for: o4-mini__ast_cfg ---\u001B[0m\n",
      "\u001B[32mINFO:   Overall Performance (Accuracy & Weighted Averages):\u001B[0m\n",
      "\u001B[32mINFO:     Accuracy:             96.58% ± 0.00%\u001B[0m\n",
      "\u001B[32mINFO:     Precision (weighted): 96.60% ± 0.00%\u001B[0m\n",
      "\u001B[32mINFO:     Recall (weighted):    96.58% ± 0.00%\u001B[0m\n",
      "\u001B[32mINFO:     F1 Score (weighted):  96.53% ± 0.00%\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "--- Results for: o4-mini__cfg ---\u001B[0m\n",
      "\u001B[32mINFO:   Overall Performance (Accuracy & Weighted Averages):\u001B[0m\n",
      "\u001B[32mINFO:     Accuracy:             94.26% ± 2.15%\u001B[0m\n",
      "\u001B[32mINFO:     Precision (weighted): 94.41% ± 2.10%\u001B[0m\n",
      "\u001B[32mINFO:     Recall (weighted):    94.26% ± 2.15%\u001B[0m\n",
      "\u001B[32mINFO:     F1 Score (weighted):  94.13% ± 2.23%\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "--- Results for: o4-mini__ast ---\u001B[0m\n",
      "\u001B[32mINFO:   Overall Performance (Accuracy & Weighted Averages):\u001B[0m\n",
      "\u001B[32mINFO:     Accuracy:             95.21% ± 0.00%\u001B[0m\n",
      "\u001B[32mINFO:     Precision (weighted): 95.19% ± 0.00%\u001B[0m\n",
      "\u001B[32mINFO:     Recall (weighted):    95.21% ± 0.00%\u001B[0m\n",
      "\u001B[32mINFO:     F1 Score (weighted):  95.15% ± 0.00%\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "--- Results for: gpt-4.1__ast_cfg ---\u001B[0m\n",
      "\u001B[32mINFO:   Overall Performance (Accuracy & Weighted Averages):\u001B[0m\n",
      "\u001B[32mINFO:     Accuracy:             91.04% ± 3.19%\u001B[0m\n",
      "\u001B[32mINFO:     Precision (weighted): 91.60% ± 2.99%\u001B[0m\n",
      "\u001B[32mINFO:     Recall (weighted):    91.04% ± 3.19%\u001B[0m\n",
      "\u001B[32mINFO:     F1 Score (weighted):  91.18% ± 3.11%\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "--- Results for: gpt-4.1__cfg ---\u001B[0m\n",
      "\u001B[32mINFO:   Overall Performance (Accuracy & Weighted Averages):\u001B[0m\n",
      "\u001B[32mINFO:     Accuracy:             91.98% ± 1.59%\u001B[0m\n",
      "\u001B[32mINFO:     Precision (weighted): 92.36% ± 0.96%\u001B[0m\n",
      "\u001B[32mINFO:     Recall (weighted):    91.98% ± 1.59%\u001B[0m\n",
      "\u001B[32mINFO:     F1 Score (weighted):  92.03% ± 1.44%\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "--- Results for: gpt-4.1__ast ---\u001B[0m\n",
      "\u001B[32mINFO:   Overall Performance (Accuracy & Weighted Averages):\u001B[0m\n",
      "\u001B[32mINFO:     Accuracy:             91.72% ± 3.04%\u001B[0m\n",
      "\u001B[32mINFO:     Precision (weighted): 92.10% ± 2.91%\u001B[0m\n",
      "\u001B[32mINFO:     Recall (weighted):    91.72% ± 3.04%\u001B[0m\n",
      "\u001B[32mINFO:     F1 Score (weighted):  91.83% ± 2.98%\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "--- Results for: gpt-4o__ast_cfg ---\u001B[0m\n",
      "\u001B[32mINFO:   Overall Performance (Accuracy & Weighted Averages):\u001B[0m\n",
      "\u001B[32mINFO:     Accuracy:             nan% ± nan%\u001B[0m\n",
      "\u001B[32mINFO:     Precision (weighted): nan% ± nan%\u001B[0m\n",
      "\u001B[32mINFO:     Recall (weighted):    nan% ± nan%\u001B[0m\n",
      "\u001B[32mINFO:     F1 Score (weighted):  nan% ± nan%\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "--- Results for: gpt-4o__cfg ---\u001B[0m\n",
      "\u001B[32mINFO:   Overall Performance (Accuracy & Weighted Averages):\u001B[0m\n",
      "\u001B[32mINFO:     Accuracy:             91.98% ± 1.37%\u001B[0m\n",
      "\u001B[32mINFO:     Precision (weighted): 92.44% ± 1.20%\u001B[0m\n",
      "\u001B[32mINFO:     Recall (weighted):    91.98% ± 1.37%\u001B[0m\n",
      "\u001B[32mINFO:     F1 Score (weighted):  92.08% ± 1.30%\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "--- Results for: gpt-4o__ast ---\u001B[0m\n",
      "\u001B[32mINFO:   Overall Performance (Accuracy & Weighted Averages):\u001B[0m\n",
      "\u001B[32mINFO:     Accuracy:             nan% ± nan%\u001B[0m\n",
      "\u001B[32mINFO:     Precision (weighted): nan% ± nan%\u001B[0m\n",
      "\u001B[32mINFO:     Recall (weighted):    nan% ± nan%\u001B[0m\n",
      "\u001B[32mINFO:     F1 Score (weighted):  nan% ± nan%\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "--- Results for: o3-mini__ast_cfg ---\u001B[0m\n",
      "\u001B[32mINFO:   Overall Performance (Accuracy & Weighted Averages):\u001B[0m\n",
      "\u001B[32mINFO:     Accuracy:             nan% ± nan%\u001B[0m\n",
      "\u001B[32mINFO:     Precision (weighted): nan% ± nan%\u001B[0m\n",
      "\u001B[32mINFO:     Recall (weighted):    nan% ± nan%\u001B[0m\n",
      "\u001B[32mINFO:     F1 Score (weighted):  nan% ± nan%\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "--- Results for: o3-mini__cfg ---\u001B[0m\n",
      "\u001B[32mINFO:   Overall Performance (Accuracy & Weighted Averages):\u001B[0m\n",
      "\u001B[32mINFO:     Accuracy:             96.56% ± 0.58%\u001B[0m\n",
      "\u001B[32mINFO:     Precision (weighted): 96.64% ± 0.62%\u001B[0m\n",
      "\u001B[32mINFO:     Recall (weighted):    96.56% ± 0.58%\u001B[0m\n",
      "\u001B[32mINFO:     F1 Score (weighted):  96.54% ± 0.59%\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "--- Results for: o3-mini__ast ---\u001B[0m\n",
      "\u001B[32mINFO:   Overall Performance (Accuracy & Weighted Averages):\u001B[0m\n",
      "\u001B[32mINFO:     Accuracy:             nan% ± nan%\u001B[0m\n",
      "\u001B[32mINFO:     Precision (weighted): nan% ± nan%\u001B[0m\n",
      "\u001B[32mINFO:     Recall (weighted):    nan% ± nan%\u001B[0m\n",
      "\u001B[32mINFO:     F1 Score (weighted):  nan% ± nan%\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "--- Results for: gpt-4.1-mini__ast_cfg ---\u001B[0m\n",
      "\u001B[32mINFO:   Overall Performance (Accuracy & Weighted Averages):\u001B[0m\n",
      "\u001B[32mINFO:     Accuracy:             85.09% ± 0.38%\u001B[0m\n",
      "\u001B[32mINFO:     Precision (weighted): 86.30% ± 1.53%\u001B[0m\n",
      "\u001B[32mINFO:     Recall (weighted):    85.09% ± 0.38%\u001B[0m\n",
      "\u001B[32mINFO:     F1 Score (weighted):  83.64% ± 0.35%\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "--- Results for: gpt-4.1-mini__cfg ---\u001B[0m\n",
      "\u001B[32mINFO:   Overall Performance (Accuracy & Weighted Averages):\u001B[0m\n",
      "\u001B[32mINFO:     Accuracy:             88.30% ± 1.01%\u001B[0m\n",
      "\u001B[32mINFO:     Precision (weighted): 88.33% ± 0.95%\u001B[0m\n",
      "\u001B[32mINFO:     Recall (weighted):    88.30% ± 1.01%\u001B[0m\n",
      "\u001B[32mINFO:     F1 Score (weighted):  88.16% ± 1.07%\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "--- Results for: gpt-4.1-mini__ast ---\u001B[0m\n",
      "\u001B[32mINFO:   Overall Performance (Accuracy & Weighted Averages):\u001B[0m\n",
      "\u001B[32mINFO:     Accuracy:             84.86% ± 1.12%\u001B[0m\n",
      "\u001B[32mINFO:     Precision (weighted): 85.96% ± 1.25%\u001B[0m\n",
      "\u001B[32mINFO:     Recall (weighted):    84.86% ± 1.12%\u001B[0m\n",
      "\u001B[32mINFO:     F1 Score (weighted):  83.66% ± 1.65%\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "--- Results for: gemini-2.5-flash-preview-05-20__ast_cfg ---\u001B[0m\n",
      "\u001B[32mINFO:   Overall Performance (Accuracy & Weighted Averages):\u001B[0m\n",
      "\u001B[32mINFO:     Accuracy:             nan% ± nan%\u001B[0m\n",
      "\u001B[32mINFO:     Precision (weighted): nan% ± nan%\u001B[0m\n",
      "\u001B[32mINFO:     Recall (weighted):    nan% ± nan%\u001B[0m\n",
      "\u001B[32mINFO:     F1 Score (weighted):  nan% ± nan%\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "--- Results for: gemini-2.5-flash-preview-05-20__cfg ---\u001B[0m\n",
      "\u001B[32mINFO:   Overall Performance (Accuracy & Weighted Averages):\u001B[0m\n",
      "\u001B[32mINFO:     Accuracy:             81.86% ± 2.17%\u001B[0m\n",
      "\u001B[32mINFO:     Precision (weighted): 92.83% ± 5.08%\u001B[0m\n",
      "\u001B[32mINFO:     Recall (weighted):    81.86% ± 2.17%\u001B[0m\n",
      "\u001B[32mINFO:     F1 Score (weighted):  85.52% ± 1.85%\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "--- Results for: gemini-2.5-flash-preview-05-20__ast ---\u001B[0m\n",
      "\u001B[32mINFO:   Overall Performance (Accuracy & Weighted Averages):\u001B[0m\n",
      "\u001B[32mINFO:     Accuracy:             nan% ± nan%\u001B[0m\n",
      "\u001B[32mINFO:     Precision (weighted): nan% ± nan%\u001B[0m\n",
      "\u001B[32mINFO:     Recall (weighted):    nan% ± nan%\u001B[0m\n",
      "\u001B[32mINFO:     F1 Score (weighted):  nan% ± nan%\u001B[0m\n",
      "\u001B[32mINFO: \n",
      "\n",
      "Processing Complete.\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Effect of Data Type",
   "id": "883bf90a83b62f1c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T06:50:48.222596Z",
     "start_time": "2025-06-12T06:50:48.210637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check if the results dictionary exists and is populated\n",
    "if 'final_classification_results' not in locals() or not isinstance(final_classification_results,\n",
    "                                                                    dict) or not final_classification_results:\n",
    "    logger.error(\"Error: 'final_classification_results' dictionary not found, is not a dictionary, or is empty.\")\n",
    "# Check if essential configuration lists exist\n",
    "elif 'data_types' not in locals() or not data_types:\n",
    "    logger.error(\"Error: 'data_types' list not found or is empty.\")\n",
    "elif 'monitored_metrics' not in locals() or not monitored_metrics:\n",
    "    logger.error(\"Error: 'monitored_metrics' list not found or is empty.\")\n",
    "else:\n",
    "    # Filter models based on the original criteria, now using the keys from the new dictionary\n",
    "    models = [\n",
    "        m for m in final_classification_results.keys()\n",
    "        if not (\"_k\" in m or m.startswith(\"r\"))  # Adjust filter if needed\n",
    "    ]\n",
    "\n",
    "    # Proceed only if there are models left after filtering\n",
    "    if not models:\n",
    "        logger.warning(\"No models match the filter criteria. No plots will be generated.\")\n",
    "    else:\n",
    "        logger.info(f\"Plotting for models: {models}\")\n",
    "        logger.info(f\"Using data types: {data_types}\")\n",
    "        logger.info(f\"Plotting metrics: {monitored_metrics}\")\n",
    "\n",
    "        # Check the exact name of the DataType column in the first valid model's DataFrame\n",
    "        first_df = final_classification_results[models[0]]\n",
    "        if \"DataType\" in first_df.columns:\n",
    "            data_type_col_name = \"DataType\"\n",
    "        elif \"Data Type\" in first_df.columns:\n",
    "            data_type_col_name = \"Data Type\"\n",
    "        else:\n",
    "            logger.error(\"Could not find 'DataType' or 'Data Type' column in DataFrames. Cannot proceed with plotting.\")\n",
    "            # Set models to empty to prevent further processing\n",
    "            models = []\n",
    "\n",
    "    # Loop through each metric to create a separate plot\n",
    "    for metric in monitored_metrics:\n",
    "        if not models:  # Skip if no models or if DataType column check failed\n",
    "            break\n",
    "\n",
    "        plt.figure(figsize=(10, 6))  # Adjust figure size as needed\n",
    "\n",
    "        # Define the column names for mean and standard deviation\n",
    "        mean_col = f\"{metric}_mean\"\n",
    "        std_col = f\"{metric}_std\"\n",
    "\n",
    "        # Basic check if mean/std columns exist in the first model's DataFrame\n",
    "        first_model_df = final_classification_results[models[0]]\n",
    "        if mean_col not in first_model_df.columns or std_col not in first_model_df.columns:\n",
    "            logger.warning(\n",
    "                f\"Metric columns '{mean_col}' or '{std_col}' not found in DataFrame for model '{models[0]}'. Skipping plot for metric '{metric}'.\")\n",
    "            plt.close()  # Close the figure created for this metric\n",
    "            continue  # Skip to the next metric\n",
    "\n",
    "        x = np.arange(len(models))  # Create base positions for the models on the x-axis\n",
    "        num_data_types = len(data_types)\n",
    "        total_width_per_model = 0.8  # Total width for all bars for one model\n",
    "        width_per_bar = total_width_per_model / num_data_types  # Width of a single bar\n",
    "\n",
    "        # Get distinct colors for each data type\n",
    "        colors = sns.color_palette(\"viridis\", num_data_types)\n",
    "\n",
    "        # Iterate through each data type to plot its bars for all models\n",
    "        for i, (data_type, color) in enumerate(zip(data_types, colors)):\n",
    "            mean_values = []\n",
    "            std_devs = []\n",
    "\n",
    "            # Gather mean and std dev for the current data_type across all selected models\n",
    "            for model in models:\n",
    "                model_df = final_classification_results[model]\n",
    "                # Find the row corresponding to the current data type\n",
    "                row = model_df.loc[model_df[data_type_col_name] == data_type]\n",
    "\n",
    "                if not row.empty:\n",
    "                    # Safely extract mean and std dev, defaulting to NaN if columns are missing (though checked earlier)\n",
    "                    mean_val = row.iloc[0].get(mean_col, np.nan)\n",
    "                    std_val = row.iloc[0].get(std_col, np.nan)\n",
    "                    mean_values.append(mean_val)\n",
    "                    # Use 0 for std dev if it's NaN but mean is valid (or handle as needed)\n",
    "                    std_devs.append(std_val if not np.isnan(std_val) else 0)\n",
    "                else:\n",
    "                    # Handle case where the data type row is missing for this model\n",
    "                    mean_values.append(np.nan)  # Append NaN to skip plotting this bar\n",
    "                    std_devs.append(np.nan)  # Append NaN for corresponding error bar\n",
    "                    logger.warning(f\"DataType '{data_type}' not found for model '{model}'. Plotting NaN.\")\n",
    "\n",
    "            # Calculate the precise x-position for this data type's bars\n",
    "            # Start from the left edge of the group, move by bar index, add half bar width\n",
    "            bar_position = x - (total_width_per_model / 2) + (i * width_per_bar) + (width_per_bar / 2)\n",
    "\n",
    "            # Plot the bars with error bars representing std dev\n",
    "            plt.bar(bar_position,\n",
    "                    mean_values,\n",
    "                    width_per_bar,\n",
    "                    yerr=std_devs,  # Use collected standard deviations for error bars\n",
    "                    label=data_type,\n",
    "                    alpha=0.8,\n",
    "                    color=color,\n",
    "                    capsize=4)  # Add caps to error bars for visibility\n",
    "\n",
    "        # --- Formatting the plot ---\n",
    "        plt.ylim([0, 1.05])  # Set Y-axis limits (adjust if metrics aren't 0-1)\n",
    "        # Set x-ticks to be centered under each group of bars\n",
    "        plt.xticks(x, models, rotation=45, ha=\"right\")\n",
    "        plt.title(f\"Comparison of {metric} Across Models (Mean ± Std Dev)\")\n",
    "        plt.xlabel(\"Model\")\n",
    "        plt.ylabel(f\"{metric} (Mean)\")\n",
    "        # Place legend outside the plot area to avoid overlap\n",
    "        plt.legend(title=\"Data Type\", loc='upper left', bbox_to_anchor=(1.02, 1))\n",
    "        plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.6)  # Add horizontal grid lines\n",
    "        # Adjust layout to make space for the legend\n",
    "        plt.tight_layout(rect=[0, 0, 0.85, 1])  # rect=[left, bottom, right, top]\n",
    "        plt.show()  # Display the plot for the current metric"
   ],
   "id": "cbc16c0761b499da",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[31mERROR: Error: 'final_classification_results' dictionary not found, is not a dictionary, or is empty.\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Models Comparison",
   "id": "ca98486f65f71bc6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T06:50:48.259862Z",
     "start_time": "2025-06-12T06:50:48.249500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check if the results dictionaries exist and are populated\n",
    "if 'final_classification_results' not in locals() or not isinstance(final_classification_results,\n",
    "                                                                    dict) or not final_classification_results:\n",
    "    logger.error(\"Error: 'final_classification_results' dictionary not found, is not a dictionary, or is empty.\")\n",
    "elif 'baseline_results' not in locals() or not isinstance(baseline_results, dict):\n",
    "    logger.error(\"Error: 'baseline_results' dictionary not found or is not a dictionary (can be empty).\")\n",
    "# Check if essential configuration lists exist\n",
    "elif 'data_types' not in locals() or not data_types:\n",
    "    logger.error(\"Error: 'data_types' list not found or is empty.\")\n",
    "elif 'monitored_metrics' not in locals() or not monitored_metrics:\n",
    "    logger.error(\"Error: 'monitored_metrics' list not found or is empty.\")\n",
    "else:\n",
    "    # Filter models based on the original criteria\n",
    "    models = [\n",
    "        m for m in final_classification_results.keys()\n",
    "        if not (\"_k\" in m or m.startswith(\"r\"))  # Adjust filter if needed\n",
    "    ]\n",
    "\n",
    "    # Proceed only if there are models left after filtering\n",
    "    if not models:\n",
    "        logger.warning(\"No models match the filter criteria. No plots will be generated.\")\n",
    "    else:\n",
    "        logger.info(f\"Plotting for models: {models}\")\n",
    "        logger.info(f\"Using data types: {data_types}\")\n",
    "        logger.info(f\"Plotting metrics: {monitored_metrics}\")\n",
    "\n",
    "        # Check the exact name of the DataType column in the first valid model's DataFrame\n",
    "        first_df = final_classification_results[models[0]]\n",
    "        if \"DataType\" in first_df.columns:\n",
    "            data_type_col_name = \"DataType\"\n",
    "        elif \"Data Type\" in first_df.columns:\n",
    "            data_type_col_name = \"Data Type\"\n",
    "        else:\n",
    "            logger.error(\"Could not find 'DataType' or 'Data Type' column in DataFrames. Cannot proceed.\")\n",
    "            models = []  # Prevent further processing\n",
    "\n",
    "    # Loop through each metric to create a separate plot\n",
    "    for metric in monitored_metrics:\n",
    "        if not models:  # Skip if no models or if DataType column check failed\n",
    "            break\n",
    "\n",
    "        plt.figure(figsize=(10, 6))  # Adjust figure size as needed\n",
    "\n",
    "        # Define the column names for mean and standard deviation\n",
    "        mean_col = f\"{metric}_mean\"\n",
    "        std_col = f\"{metric}_std\"\n",
    "\n",
    "        # Basic check if mean/std columns exist in the first model's DataFrame (for main results)\n",
    "        first_model_df = final_classification_results[models[0]]\n",
    "        if mean_col not in first_model_df.columns or std_col not in first_model_df.columns:\n",
    "            logger.warning(\n",
    "                f\"Main result columns '{mean_col}' or '{std_col}' not found in DataFrame for model '{models[0]}'. Skipping plot for metric '{metric}'.\")\n",
    "            plt.close()\n",
    "            continue\n",
    "\n",
    "        x = np.arange(len(data_types))  # Base positions for the data types on the x-axis\n",
    "        num_models = len(models)\n",
    "        total_width_per_group = 0.8  # Total width for all bars for one data type\n",
    "        width_per_bar = total_width_per_group / num_models  # Width of a single bar\n",
    "\n",
    "        # Get distinct colors for each model and store them\n",
    "        model_colors = {model: color for model, color in zip(models, sns.color_palette(\"viridis\", num_models))}\n",
    "\n",
    "        # --- Plot Baseline Bars First (Faded, Hatched, With Error Bars, No Label) ---\n",
    "        for i, model in enumerate(models):\n",
    "            # Get the baseline mean and std dev for this model and metric (assuming 'overall' structure)\n",
    "            baseline_mean = baseline_results.get(model, {}).get('overall', {}).get(mean_col, np.nan)\n",
    "            baseline_std = baseline_results.get(model, {}).get('overall', {}).get(std_col, np.nan)  # Get std dev\n",
    "\n",
    "            if np.isnan(baseline_mean):\n",
    "                logger.warning(\n",
    "                    f\"Baseline mean for model '{model}', metric '{metric}' not found. Skipping baseline bar.\")\n",
    "                # Skip plotting if mean is NaN\n",
    "                continue\n",
    "            # If std dev is NaN but mean is valid, default std dev to 0 for plotting\n",
    "            if np.isnan(baseline_std):\n",
    "                logger.warning(\n",
    "                    f\"Baseline std dev for model '{model}', metric '{metric}' not found. Plotting baseline bar with 0 std dev.\")\n",
    "                baseline_std = 0\n",
    "\n",
    "            # Create lists of baseline values, repeated for each data type\n",
    "            baseline_means_list = [baseline_mean] * len(data_types)\n",
    "            baseline_stds_list = [baseline_std] * len(data_types)  # Create list for std dev\n",
    "\n",
    "            # Calculate the precise x-position for this model's bars\n",
    "            bar_position = x - (total_width_per_group / 2) + (i * width_per_bar) + (width_per_bar / 2)\n",
    "\n",
    "            color = model_colors.get(model, \"gray\")  # Use stored color\n",
    "\n",
    "            plt.bar(bar_position,\n",
    "                    baseline_means_list,\n",
    "                    width_per_bar,\n",
    "                    yerr=baseline_stds_list,  # Add baseline error bars\n",
    "                    alpha=0.4,  # Lower alpha for baseline\n",
    "                    color=color,\n",
    "                    error_kw=dict(ecolor='gray'),\n",
    "                    capsize=3,  # Slightly smaller capsize for baseline\n",
    "                    hatch='//')  # Add hatching for distinction\n",
    "            # No label here\n",
    "\n",
    "        # --- Plot Main Bars Second (Solid, With Label and Error Bars) ---\n",
    "        for i, model in enumerate(models):\n",
    "            model_df = final_classification_results[model]\n",
    "            mean_values = []\n",
    "            std_devs = []\n",
    "\n",
    "            # Gather mean and std dev for the current model across all data types\n",
    "            for dt in data_types:\n",
    "                row = model_df.loc[model_df[data_type_col_name] == dt]\n",
    "                if not row.empty:\n",
    "                    mean_val = row.iloc[0].get(mean_col, np.nan)\n",
    "                    std_val = row.iloc[0].get(std_col, np.nan)\n",
    "                    mean_values.append(mean_val)\n",
    "                    # Default std dev to 0 if NaN but mean is valid\n",
    "                    std_devs.append(std_val if not np.isnan(std_val) else 0)\n",
    "                else:\n",
    "                    mean_values.append(np.nan)\n",
    "                    std_devs.append(np.nan)\n",
    "                    logger.warning(f\"Model '{model}': DataType '{dt}' row not found. Plotting NaN.\")\n",
    "\n",
    "            # Calculate the precise x-position for this model's bars (same as baseline)\n",
    "            bar_position = x - (total_width_per_group / 2) + (i * width_per_bar) + (width_per_bar / 2)\n",
    "            color = model_colors.get(model, \"gray\")  # Use stored color\n",
    "\n",
    "            # Plot the main bars with error bars\n",
    "            plt.bar(bar_position,\n",
    "                    mean_values,\n",
    "                    width_per_bar,\n",
    "                    yerr=std_devs,  # Use collected standard deviations\n",
    "                    label=model,  # Label for the legend\n",
    "                    alpha=0.9,  # Higher alpha for main bars\n",
    "                    color=color,  # Use the model's assigned color\n",
    "                    capsize=5)  # Larger capsize for main error bars\n",
    "\n",
    "        # --- Formatting the plot ---\n",
    "        plt.ylim([0, 1.05])  # Set Y-axis limits\n",
    "        # Set x-ticks to be centered under each group of bars (i.e., at data type positions)\n",
    "        plt.xticks(x, data_types)\n",
    "        # Update title to reflect both bars show Mean +/- SD\n",
    "        plt.title(f\"Comparison of {metric} (Mean±SD): Model (Solid) vs Baseline (Hatched/Faded)\")\n",
    "        plt.xlabel(\"Data Type\")\n",
    "        plt.ylabel(f\"{metric} (Mean)\")\n",
    "        # Create legend (model names only)\n",
    "        plt.legend(title=\"Model\", loc='upper left', bbox_to_anchor=(1.02, 1))\n",
    "        plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.6)  # Add horizontal grid lines\n",
    "        # Adjust layout to make space for the legend\n",
    "        plt.tight_layout(rect=[0, 0, 0.85, 1])  # rect=[left, bottom, right, top]\n",
    "        plt.show()  # Display the plot for the current metric"
   ],
   "id": "8c11cbf9d99c23a0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[31mERROR: Error: 'final_classification_results' dictionary not found, is not a dictionary, or is empty.\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
