#!/bin/bash
#
# Runs the explanation evaluation pipeline.
# This script uses a specified 'evaluator' model to score explanations
# generated by one or more 'target' models across all cross-validation splits.
#
# Usage:
#   ./src/scripts/eval_explanations.sh [--evaluator EVALUATOR_MODEL] [TARGET_MODEL_1] [TARGET_MODEL_2] ...
#
# Examples:
#   # Evaluate explanations from 'gpt-4.1' and 'o3-mini' using the default evaluator ('o4-mini')
#   ./src/scripts/eval_explanations.sh gpt-4.1 o3-mini
#
#   # Evaluate explanations from 'gpt-4.1' using 'gpt-4o' as the evaluator
#   ./src/scripts/eval_explanations.sh --evaluator gpt-4o gpt-4.1

# --- Configuration ---
VENV_PATH=".venv"
PYTHON_SCRIPT="src/scripts/eval_explanations.py"
NUM_CV_SPLITS=5
DEFAULT_TARGET_MODELS=("gpt-4.1" "o3-mini")
DEFAULT_EVALUATOR_MODEL="o4-mini"

# --- Script Logic ---
set -e # Exit immediately if a command exits with a non-zero status.

# --- Functions ---
print_usage() {
    echo "Usage: $0 [--evaluator EVALUATOR_MODEL] [TARGET_MODEL_1] [TARGET_MODEL_2] ..."
    echo "Uses an 'evaluator' model to score explanations from 'target' models."
    echo ""
    echo "Arguments:"
    echo "  --evaluator    The model to use for scoring (default: $DEFAULT_EVALUATOR_MODEL)."
    echo "  TARGET_MODEL   One or more models whose explanations you want to evaluate."
    echo ""
    echo "If no target models are specified, it defaults to: ${DEFAULT_TARGET_MODELS[*]}"
}

# --- Argument Parsing ---
EVALUATOR_MODEL="$DEFAULT_EVALUATOR_MODEL"
TARGET_MODELS=()

while [[ $# -gt 0 ]]; do
    case $1 in
        -h|--help)
            print_usage
            exit 0
            ;;
        --evaluator)
            if [ -n "$2" ] && [ ${2:0:1} != "-" ]; then
                EVALUATOR_MODEL="$2"
                shift 2
            else
                echo "Error: --evaluator requires a non-empty argument." >&2
                exit 1
            fi
            ;;
        *)
            TARGET_MODELS+=("$1") # Save positional arg
            shift # Past argument
            ;;
    esac
done

# If no target models were provided as arguments, use the defaults
if [ ${#TARGET_MODELS[@]} -eq 0 ]; then
    echo "[INFO] No target models specified. Using defaults: ${DEFAULT_TARGET_MODELS[*]}"
    TARGET_MODELS=("${DEFAULT_TARGET_MODELS[@]}")
fi

# --- Pre-run Checks ---
if [ ! -d "$VENV_PATH" ]; then
    echo "[ERROR] Virtual environment not found at '$VENV_PATH'. Please create it first."
    exit 1
fi

if [ ! -f "$PYTHON_SCRIPT" ]; then
    echo "[ERROR] Python script not found at '$PYTHON_SCRIPT'."
    exit 1
fi

# --- Execution ---
source "$VENV_PATH/bin/activate"
export PYTHONPATH=$(pwd)/src:$PYTHONPATH

echo "[INFO] Starting explanation evaluation."
echo "[INFO] Evaluator Model: $EVALUATOR_MODEL"
echo "[INFO] Target Models to Evaluate: ${TARGET_MODELS[*]}"

# Loop through each cross-validation split
for i in $(seq 1 $NUM_CV_SPLITS); do
    DATASET_PATH="cv_splits/cv_split_${i}/test"
    echo "======================================================"
    echo "[INFO] Processing Cross-Validation Split ${i}/${NUM_CV_SPLITS}"
    echo "======================================================"

    # Loop through each target model
    for TARGET_MODEL in "${TARGET_MODELS[@]}"; do
        echo "[INFO] Evaluating explanations from model: $TARGET_MODEL"

        python3 "$PYTHON_SCRIPT" \
            --dataset-path "$DATASET_PATH" \
            --model-name "$TARGET_MODEL" \
            --evaluator "$EVALUATOR_MODEL"

        echo "[INFO] Finished evaluating explanations from model: $TARGET_MODEL."
        echo "------------------------------------------------------"
    done
done

echo "[SUCCESS] All explanation evaluations completed successfully!"